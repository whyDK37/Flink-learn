12:35:06.973 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:06.973 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 21 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:06.973 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1219) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:06.973 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:07.476 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:07.476 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 21 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:07.476 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1220) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:07.476 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:07.981 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:07.981 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 21 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:07.981 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1221) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:07.981 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:08.486 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:08.486 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 21 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:08.486 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1222) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:08.486 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:08.990 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:08.990 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 21 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:08.991 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1223) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:08.991 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:09.493 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:09.493 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 21 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:09.493 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1224) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:09.493 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:09.782 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=21, metadata=''}}
12:35:09.783 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 21 for partition test-0
12:35:09.783 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=21, metadata=''}}
12:35:09.995 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:09.995 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 21 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:09.995 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1225) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:09.995 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:10.502 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:10.503 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 21 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:10.503 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1226) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:10.503 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:11.006 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:11.006 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 21 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:11.006 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1227) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:11.006 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:11.083 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 1 response partition(s)
12:35:11.083 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Fetch READ_UNCOMMITTED at offset 21 for partition test-0 returned fetch data (error=NONE, highWaterMark=22, lastStableOffset = 22, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=70)
12:35:11.084 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:11.084 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1228) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:11.084 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(test-0), toForget=(), implied=()) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
kafka:ee
7> ee
7> (ee,3)
12:35:11.169 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 23] start execution
12:35:11.170 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:35:11.171 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:35:11.171 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:35:11.171 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 23] Request connection for {}->http://127.0.0.1:9200
12:35:11.171 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:35:11.171 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:35:11.171 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-1][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:35:11.174 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 23] Connection allocated: CPoolProxy{http-outgoing-1 [ACTIVE]}
12:35:11.174 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:35:11.175 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][rw:r]: Event set [w]
12:35:11.175 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [ACTIVE] Request ready
12:35:11.175 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 23] Attempt 1 to execute request
12:35:11.175 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 23] Target auth state: UNCHALLENGED
12:35:11.175 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 23] Proxy auth state: UNCHALLENGED
12:35:11.175 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:35:11.175 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 >> POST /_bulk?timeout=1m HTTP/1.1
12:35:11.175 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 >> Content-Length: 103
12:35:11.175 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 >> Content-Type: application/json
12:35:11.175 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 >> Host: 127.0.0.1:9200
12:35:11.175 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 >> Connection: Keep-Alive
12:35:11.175 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:35:11.176 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:35:11.176 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [ACTIVE] Output ready
12:35:11.176 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 23] produce content
12:35:11.176 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 23] Request completed
12:35:11.176 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [ACTIVE] [content length: 103; pos: 103; completed: true]
12:35:11.176 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][rw:w]: 293 bytes written
12:35:11.176 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:35:11.176 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "Content-Length: 103[\r][\n]"
12:35:11.177 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "Content-Type: application/json[\r][\n]"
12:35:11.177 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "Host: 127.0.0.1:9200[\r][\n]"
12:35:11.177 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
12:35:11.177 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:35:11.177 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "[\r][\n]"
12:35:11.177 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"ee"}}[\n]"
12:35:11.177 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "{"doc_as_upsert":true,"doc":{"status":3}}[\n]"
12:35:11.177 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [ACTIVE] Request ready
12:35:11.178 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:35:11.586 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:11.586 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:11.586 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1229) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:11.586 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:12.045 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][r:r]: 417 bytes read
12:35:12.045 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 << "HTTP/1.1 200 OK[\r][\n]"
12:35:12.046 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 << "Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."[\r][\n]"
12:35:12.046 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 << "content-type: application/json; charset=UTF-8[\r][\n]"
12:35:12.046 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 << "content-length: 221[\r][\n]"
12:35:12.046 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 << "[\r][\n]"
12:35:12.046 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 << "{"took":866,"errors":false,"items":[{"update":{"_index":"test_index","_type":"_doc","_id":"ee","_version":1,"result":"created","_shards":{"total":2,"successful":2,"failed":0},"_seq_no":9,"_primary_term":1,"status":201}}]}"
12:35:12.048 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 << HTTP/1.1 200 OK
12:35:12.048 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 << Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."
12:35:12.048 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 << content-type: application/json; charset=UTF-8
12:35:12.048 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 << content-length: 221
12:35:12.048 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [ACTIVE(221)] Response received
12:35:12.048 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 23] Response received HTTP/1.1 200 OK
12:35:12.048 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [ACTIVE(221)] Input ready
12:35:12.048 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 23] Consume content
12:35:12.048 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 23] Connection can be kept alive indefinitely
12:35:12.048 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 23] Response processed
12:35:12.048 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 23] releasing connection
12:35:12.048 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][r:r]: Remove attribute http.nio.exchange-handler
12:35:12.049 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-1][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:35:12.049 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection [id: http-outgoing-1][route: {}->http://127.0.0.1:9200] can be kept alive indefinitely
12:35:12.049 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:35:12.049 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-1][route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:35:12.049 [I/O dispatcher 49] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned [HTTP/1.1 200 OK]
12:35:12.050 [I/O dispatcher 49] WARN org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."]
12:35:12.052 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [ACTIVE] [content length: 221; pos: 221; completed: true]
12:35:12.089 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:12.090 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:12.090 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1230) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:12.090 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:12.520 [flink-akka.actor.default-dispatcher-105] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:35:12.520 [flink-akka.actor.default-dispatcher-111] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:35:12.521 [flink-akka.actor.default-dispatcher-105] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:35:12.521 [flink-akka.actor.default-dispatcher-111] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:35:12.521 [flink-akka.actor.default-dispatcher-111] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 621afbc6d2b245ff6afa7759e6d8da3a.
12:35:12.521 [flink-akka.actor.default-dispatcher-112] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:12.522 [flink-akka.actor.default-dispatcher-112] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received new slot report from TaskManager 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:12.522 [flink-akka.actor.default-dispatcher-112] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Received slot report from instance f2876166ab70148059ed9f2f9a72cef9.
12:35:12.593 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:12.593 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:12.593 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1231) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:12.593 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:13.094 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:13.095 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:13.095 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1232) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:13.095 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:13.596 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:13.597 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:13.597 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1233) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:13.597 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:13.910 [flink-akka.actor.default-dispatcher-112] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
12:35:13.910 [flink-akka.actor.default-dispatcher-105] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from 621afbc6d2b245ff6afa7759e6d8da3a.
12:35:13.911 [flink-akka.actor.default-dispatcher-105] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:14.098 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:14.098 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:14.098 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1234) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:14.098 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:14.602 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:14.602 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:14.602 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1235) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:14.602 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:14.782 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:14.786 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 22 for partition test-0
12:35:14.786 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:15.104 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:15.104 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:15.104 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1236) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:15.104 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:15.607 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:15.607 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:15.607 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1237) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:15.607 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:16.110 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:16.110 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:16.111 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1238) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:16.111 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:16.613 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:16.613 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:16.613 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1239) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:16.613 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:17.116 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:17.116 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:17.116 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1240) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:17.116 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:17.618 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:17.618 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:17.618 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1241) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:17.618 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:18.120 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:18.120 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:18.120 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1242) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:18.120 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:18.623 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:18.623 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:18.623 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1243) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:18.623 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:19.128 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:19.128 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:19.128 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1244) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:19.128 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:19.630 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:19.630 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:19.630 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1245) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:19.630 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:19.782 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:19.786 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 22 for partition test-0
12:35:19.786 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:20.131 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:20.131 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:20.132 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1246) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:20.132 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:20.634 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:20.634 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:20.634 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1247) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:20.634 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:21.136 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:21.136 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:21.136 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1248) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:21.136 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:21.639 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:21.639 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:21.639 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1249) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:21.639 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:22.143 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:22.143 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:22.143 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1250) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:22.143 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:22.522 [flink-akka.actor.default-dispatcher-111] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:35:22.523 [flink-akka.actor.default-dispatcher-113] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:35:22.524 [flink-akka.actor.default-dispatcher-113] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:22.524 [flink-akka.actor.default-dispatcher-113] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received new slot report from TaskManager 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:22.524 [flink-akka.actor.default-dispatcher-113] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Received slot report from instance f2876166ab70148059ed9f2f9a72cef9.
12:35:22.533 [flink-akka.actor.default-dispatcher-114] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:35:22.533 [flink-akka.actor.default-dispatcher-113] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:35:22.534 [flink-akka.actor.default-dispatcher-114] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 621afbc6d2b245ff6afa7759e6d8da3a.
12:35:22.646 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:22.646 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:22.646 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1251) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:22.646 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:23.150 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:23.150 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:23.150 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1252) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:23.150 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:23.652 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:23.652 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:23.652 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1253) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:23.652 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:23.909 [flink-akka.actor.default-dispatcher-114] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
12:35:23.910 [flink-akka.actor.default-dispatcher-113] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from 621afbc6d2b245ff6afa7759e6d8da3a.
12:35:23.910 [flink-akka.actor.default-dispatcher-113] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:24.155 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:24.155 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:24.155 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1254) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:24.155 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:24.658 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:24.658 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:24.658 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1255) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:24.658 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:24.783 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:24.787 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 22 for partition test-0
12:35:24.787 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:25.161 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:25.161 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:25.161 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1256) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:25.161 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:25.662 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:25.662 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:25.662 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1257) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:25.662 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:26.165 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:26.165 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:26.165 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1258) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:26.165 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:26.667 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:26.667 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:26.667 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1259) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:26.667 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:27.170 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:27.170 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:27.170 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1260) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:27.170 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:27.673 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:27.673 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:27.673 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1261) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:27.673 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:28.176 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:28.176 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:28.176 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1262) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:28.176 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:28.679 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:28.679 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:28.679 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1263) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:28.679 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:29.181 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:29.181 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:29.181 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1264) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:29.181 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:29.684 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:29.684 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:29.685 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1265) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:29.685 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:29.784 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:29.787 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 22 for partition test-0
12:35:29.787 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:30.188 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:30.188 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:30.188 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1266) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:30.188 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:30.688 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:30.688 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:30.688 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1267) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:30.689 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:31.190 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:31.190 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:31.190 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1268) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:31.190 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:31.693 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:31.694 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:31.694 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1269) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:31.694 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:32.195 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:32.195 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:32.195 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1270) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:32.195 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:32.524 [flink-akka.actor.default-dispatcher-111] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:35:32.524 [flink-akka.actor.default-dispatcher-114] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:35:32.525 [flink-akka.actor.default-dispatcher-114] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:35:32.525 [flink-akka.actor.default-dispatcher-111] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:35:32.526 [flink-akka.actor.default-dispatcher-115] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 621afbc6d2b245ff6afa7759e6d8da3a.
12:35:32.526 [flink-akka.actor.default-dispatcher-116] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:32.527 [flink-akka.actor.default-dispatcher-116] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received new slot report from TaskManager 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:32.527 [flink-akka.actor.default-dispatcher-116] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Received slot report from instance f2876166ab70148059ed9f2f9a72cef9.
12:35:32.698 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:32.698 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:32.698 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1271) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:32.698 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:33.199 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:33.199 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:33.199 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1272) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:33.199 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:33.701 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:33.701 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:33.701 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1273) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:33.701 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:33.903 [flink-akka.actor.default-dispatcher-116] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
12:35:33.903 [flink-akka.actor.default-dispatcher-116] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from 621afbc6d2b245ff6afa7759e6d8da3a.
12:35:33.905 [flink-akka.actor.default-dispatcher-111] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:34.204 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:34.204 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:34.204 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1274) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:34.204 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:34.706 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:34.706 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:34.706 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1275) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:34.706 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:34.784 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:34.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 22 for partition test-0
12:35:34.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:34.803 [flink-akka.actor.default-dispatcher-111] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Slot Pool Status:
	status: connected to akka://flink/user/resourcemanager_561724c3-ac3d-4ded-b450-27d306344362
	registered TaskManagers: [44d9f797-9615-4b31-b456-531e5238ff73]
	available slots: []
	allocated slots: [[AllocatedSlot AllocationID{75e09d17a2942a3065f51a6840a482ff} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 6, AllocatedSlot AllocationID{f13cb848b24e3e3e8e733b16004e062c} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 7, AllocatedSlot AllocationID{c0b004201bfbe3400cc808c96d8b8365} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 4, AllocatedSlot AllocationID{e758aac1ee5da11a6e9011f3605acd4f} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 1, AllocatedSlot AllocationID{9acab6076aac22871be5d350fba4ca31} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 0, AllocatedSlot AllocationID{05edcf935db937ae387c68dced2a94e4} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 3, AllocatedSlot AllocationID{ff0ef514b2463d2406ff304b42249356} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 2, AllocatedSlot AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 5]]
	pending requests: []
	sharing groups: {
	 -------- 576517cdb14ffcc6d1732962d417e42c --------
{
	groupId=576517cdb14ffcc6d1732962d417e42c
	unresolved={}
	resolved={44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1)=[MultiTaskSlot{requestId=SlotRequestId{2ea0871f39adc261baa4877ff3415202}, allocatedRequestId=SlotRequestId{67a6754dd39c86e1c29ff920a1ef76b2}, groupId=null, physicalSlot=AllocatedSlot AllocationID{05edcf935db937ae387c68dced2a94e4} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 3, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}, allocationId=AllocationID{05edcf935db937ae387c68dced2a94e4}), request=SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}, allocationId=AllocationID{05edcf935db937ae387c68dced2a94e4}), request=SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}, group=0a448493b4782967b150582570326227}]}, MultiTaskSlot{requestId=SlotRequestId{2a8e814a4731561378a993c0af76a933}, allocatedRequestId=SlotRequestId{6715ab7ec90dcfc0995fb5a87f03d354}, groupId=null, physicalSlot=AllocatedSlot AllocationID{9acab6076aac22871be5d350fba4ca31} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 0, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{887aa3ffc53e7b6ba987097678262d04}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{887aa3ffc53e7b6ba987097678262d04}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}, group=bc764cd8ddf7a0cff126f51c16239658}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{295c6c46a79d94283fa95042835e7518}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{295c6c46a79d94283fa95042835e7518}, group=0a448493b4782967b150582570326227}]}, MultiTaskSlot{requestId=SlotRequestId{736b8c6e155757c3cee0e39e16d9e44e}, allocatedRequestId=SlotRequestId{b1184ccf75ed3811528066775a34df21}, groupId=null, physicalSlot=AllocatedSlot AllocationID{f13cb848b24e3e3e8e733b16004e062c} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 7, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}, allocationId=AllocationID{f13cb848b24e3e3e8e733b16004e062c}), request=SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{ebd1ead0866ead21574aca31c67c747f}, allocationId=AllocationID{f13cb848b24e3e3e8e733b16004e062c}), request=SlotRequestId{ebd1ead0866ead21574aca31c67c747f}, group=0a448493b4782967b150582570326227}]}, MultiTaskSlot{requestId=SlotRequestId{aae221589bd5ca1f5951ce5b6cbe9397}, allocatedRequestId=SlotRequestId{23fb6480c6d050fb7421929760796332}, groupId=null, physicalSlot=AllocatedSlot AllocationID{c0b004201bfbe3400cc808c96d8b8365} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 4, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{6ae167cf815b656fd674e788559c727b}, allocationId=AllocationID{c0b004201bfbe3400cc808c96d8b8365}), request=SlotRequestId{6ae167cf815b656fd674e788559c727b}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}, allocationId=AllocationID{c0b004201bfbe3400cc808c96d8b8365}), request=SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}, group=0a448493b4782967b150582570326227}]}, MultiTaskSlot{requestId=SlotRequestId{a4e7689e9482fcb1b182017d220949d0}, allocatedRequestId=SlotRequestId{a63e244e13b46e0ec7cbe04c71b901dc}, groupId=null, physicalSlot=AllocatedSlot AllocationID{e758aac1ee5da11a6e9011f3605acd4f} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 1, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}, group=bc764cd8ddf7a0cff126f51c16239658}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{eb3f2c3195da229322e366bb5f054331}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{eb3f2c3195da229322e366bb5f054331}, group=0a448493b4782967b150582570326227}]}, MultiTaskSlot{requestId=SlotRequestId{7a254ff1e52d1c0d0d5e762f2782359f}, allocatedRequestId=SlotRequestId{44f4cbbbaf936a8acbeab99e3e6c5efb}, groupId=null, physicalSlot=AllocatedSlot AllocationID{75e09d17a2942a3065f51a6840a482ff} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 6, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}, allocationId=AllocationID{75e09d17a2942a3065f51a6840a482ff}), request=SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{8025cceab9f3884a0d5456814df81e66}, allocationId=AllocationID{75e09d17a2942a3065f51a6840a482ff}), request=SlotRequestId{8025cceab9f3884a0d5456814df81e66}, group=0a448493b4782967b150582570326227}]}, MultiTaskSlot{requestId=SlotRequestId{f85c81b8333fdf15e365d94f1a2aef3b}, allocatedRequestId=SlotRequestId{9225a682112ba3a8876a86624954f883}, groupId=null, physicalSlot=AllocatedSlot AllocationID{ff0ef514b2463d2406ff304b42249356} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 2, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{137314c001a9aa59f0514fb84a745561}, allocationId=AllocationID{ff0ef514b2463d2406ff304b42249356}), request=SlotRequestId{137314c001a9aa59f0514fb84a745561}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}, allocationId=AllocationID{ff0ef514b2463d2406ff304b42249356}), request=SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}, group=0a448493b4782967b150582570326227}]}, MultiTaskSlot{requestId=SlotRequestId{5033a864b671b2b3de3442756ff36370}, allocatedRequestId=SlotRequestId{3e7bd6b7d6e68acec9696656a198d3a6}, groupId=null, physicalSlot=AllocatedSlot AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 5, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}, allocationId=AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d}), request=SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{c5bc5ddca88560402317a675a5a740fe}, allocationId=AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d}), request=SlotRequestId{c5bc5ddca88560402317a675a5a740fe}, group=0a448493b4782967b150582570326227}]}]}
	all={SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}, allocationId=AllocationID{05edcf935db937ae387c68dced2a94e4}), request=SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}, group=51397532e2d9c7a21097a30d590b3114}, SlotRequestId{6ae167cf815b656fd674e788559c727b}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{6ae167cf815b656fd674e788559c727b}, allocationId=AllocationID{c0b004201bfbe3400cc808c96d8b8365}), request=SlotRequestId{6ae167cf815b656fd674e788559c727b}, group=51397532e2d9c7a21097a30d590b3114}, SlotRequestId{295c6c46a79d94283fa95042835e7518}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{295c6c46a79d94283fa95042835e7518}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{295c6c46a79d94283fa95042835e7518}, group=0a448493b4782967b150582570326227}, SlotRequestId{887aa3ffc53e7b6ba987097678262d04}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{887aa3ffc53e7b6ba987097678262d04}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{887aa3ffc53e7b6ba987097678262d04}, group=51397532e2d9c7a21097a30d590b3114}, SlotRequestId{2a8e814a4731561378a993c0af76a933}=MultiTaskSlot{requestId=SlotRequestId{2a8e814a4731561378a993c0af76a933}, allocatedRequestId=SlotRequestId{6715ab7ec90dcfc0995fb5a87f03d354}, groupId=null, physicalSlot=AllocatedSlot AllocationID{9acab6076aac22871be5d350fba4ca31} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 0, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{887aa3ffc53e7b6ba987097678262d04}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{887aa3ffc53e7b6ba987097678262d04}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}, group=bc764cd8ddf7a0cff126f51c16239658}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{295c6c46a79d94283fa95042835e7518}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{295c6c46a79d94283fa95042835e7518}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}, allocationId=AllocationID{c0b004201bfbe3400cc808c96d8b8365}), request=SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}, group=0a448493b4782967b150582570326227}, SlotRequestId{aae221589bd5ca1f5951ce5b6cbe9397}=MultiTaskSlot{requestId=SlotRequestId{aae221589bd5ca1f5951ce5b6cbe9397}, allocatedRequestId=SlotRequestId{23fb6480c6d050fb7421929760796332}, groupId=null, physicalSlot=AllocatedSlot AllocationID{c0b004201bfbe3400cc808c96d8b8365} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 4, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{6ae167cf815b656fd674e788559c727b}, allocationId=AllocationID{c0b004201bfbe3400cc808c96d8b8365}), request=SlotRequestId{6ae167cf815b656fd674e788559c727b}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}, allocationId=AllocationID{c0b004201bfbe3400cc808c96d8b8365}), request=SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{5033a864b671b2b3de3442756ff36370}=MultiTaskSlot{requestId=SlotRequestId{5033a864b671b2b3de3442756ff36370}, allocatedRequestId=SlotRequestId{3e7bd6b7d6e68acec9696656a198d3a6}, groupId=null, physicalSlot=AllocatedSlot AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 5, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}, allocationId=AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d}), request=SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{c5bc5ddca88560402317a675a5a740fe}, allocationId=AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d}), request=SlotRequestId{c5bc5ddca88560402317a675a5a740fe}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}, group=bc764cd8ddf7a0cff126f51c16239658}, SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}, group=51397532e2d9c7a21097a30d590b3114}, SlotRequestId{7a254ff1e52d1c0d0d5e762f2782359f}=MultiTaskSlot{requestId=SlotRequestId{7a254ff1e52d1c0d0d5e762f2782359f}, allocatedRequestId=SlotRequestId{44f4cbbbaf936a8acbeab99e3e6c5efb}, groupId=null, physicalSlot=AllocatedSlot AllocationID{75e09d17a2942a3065f51a6840a482ff} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 6, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}, allocationId=AllocationID{75e09d17a2942a3065f51a6840a482ff}), request=SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{8025cceab9f3884a0d5456814df81e66}, allocationId=AllocationID{75e09d17a2942a3065f51a6840a482ff}), request=SlotRequestId{8025cceab9f3884a0d5456814df81e66}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}, allocationId=AllocationID{75e09d17a2942a3065f51a6840a482ff}), request=SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}, group=51397532e2d9c7a21097a30d590b3114}, SlotRequestId{c5bc5ddca88560402317a675a5a740fe}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{c5bc5ddca88560402317a675a5a740fe}, allocationId=AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d}), request=SlotRequestId{c5bc5ddca88560402317a675a5a740fe}, group=0a448493b4782967b150582570326227}, SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}, allocationId=AllocationID{05edcf935db937ae387c68dced2a94e4}), request=SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}, group=0a448493b4782967b150582570326227}, SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}, group=bc764cd8ddf7a0cff126f51c16239658}, SlotRequestId{2ea0871f39adc261baa4877ff3415202}=MultiTaskSlot{requestId=SlotRequestId{2ea0871f39adc261baa4877ff3415202}, allocatedRequestId=SlotRequestId{67a6754dd39c86e1c29ff920a1ef76b2}, groupId=null, physicalSlot=AllocatedSlot AllocationID{05edcf935db937ae387c68dced2a94e4} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 3, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}, allocationId=AllocationID{05edcf935db937ae387c68dced2a94e4}), request=SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}, allocationId=AllocationID{05edcf935db937ae387c68dced2a94e4}), request=SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{eb3f2c3195da229322e366bb5f054331}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{eb3f2c3195da229322e366bb5f054331}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{eb3f2c3195da229322e366bb5f054331}, group=0a448493b4782967b150582570326227}, SlotRequestId{a4e7689e9482fcb1b182017d220949d0}=MultiTaskSlot{requestId=SlotRequestId{a4e7689e9482fcb1b182017d220949d0}, allocatedRequestId=SlotRequestId{a63e244e13b46e0ec7cbe04c71b901dc}, groupId=null, physicalSlot=AllocatedSlot AllocationID{e758aac1ee5da11a6e9011f3605acd4f} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 1, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}, group=bc764cd8ddf7a0cff126f51c16239658}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{eb3f2c3195da229322e366bb5f054331}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{eb3f2c3195da229322e366bb5f054331}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}, allocationId=AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d}), request=SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}, group=51397532e2d9c7a21097a30d590b3114}, SlotRequestId{f85c81b8333fdf15e365d94f1a2aef3b}=MultiTaskSlot{requestId=SlotRequestId{f85c81b8333fdf15e365d94f1a2aef3b}, allocatedRequestId=SlotRequestId{9225a682112ba3a8876a86624954f883}, groupId=null, physicalSlot=AllocatedSlot AllocationID{ff0ef514b2463d2406ff304b42249356} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 2, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{137314c001a9aa59f0514fb84a745561}, allocationId=AllocationID{ff0ef514b2463d2406ff304b42249356}), request=SlotRequestId{137314c001a9aa59f0514fb84a745561}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}, allocationId=AllocationID{ff0ef514b2463d2406ff304b42249356}), request=SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}, allocationId=AllocationID{f13cb848b24e3e3e8e733b16004e062c}), request=SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}, group=51397532e2d9c7a21097a30d590b3114}, SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}, allocationId=AllocationID{ff0ef514b2463d2406ff304b42249356}), request=SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}, group=0a448493b4782967b150582570326227}, SlotRequestId{ebd1ead0866ead21574aca31c67c747f}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{ebd1ead0866ead21574aca31c67c747f}, allocationId=AllocationID{f13cb848b24e3e3e8e733b16004e062c}), request=SlotRequestId{ebd1ead0866ead21574aca31c67c747f}, group=0a448493b4782967b150582570326227}, SlotRequestId{736b8c6e155757c3cee0e39e16d9e44e}=MultiTaskSlot{requestId=SlotRequestId{736b8c6e155757c3cee0e39e16d9e44e}, allocatedRequestId=SlotRequestId{b1184ccf75ed3811528066775a34df21}, groupId=null, physicalSlot=AllocatedSlot AllocationID{f13cb848b24e3e3e8e733b16004e062c} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 7, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}, allocationId=AllocationID{f13cb848b24e3e3e8e733b16004e062c}), request=SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{ebd1ead0866ead21574aca31c67c747f}, allocationId=AllocationID{f13cb848b24e3e3e8e733b16004e062c}), request=SlotRequestId{ebd1ead0866ead21574aca31c67c747f}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{8025cceab9f3884a0d5456814df81e66}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{8025cceab9f3884a0d5456814df81e66}, allocationId=AllocationID{75e09d17a2942a3065f51a6840a482ff}), request=SlotRequestId{8025cceab9f3884a0d5456814df81e66}, group=0a448493b4782967b150582570326227}, SlotRequestId{137314c001a9aa59f0514fb84a745561}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{137314c001a9aa59f0514fb84a745561}, allocationId=AllocationID{ff0ef514b2463d2406ff304b42249356}), request=SlotRequestId{137314c001a9aa59f0514fb84a745561}, group=51397532e2d9c7a21097a30d590b3114}}
}	}

12:35:35.209 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:35.209 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:35.209 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1276) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:35.209 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:35.712 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:35.712 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:35.712 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1277) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:35.712 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:36.215 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:36.215 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:36.215 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1278) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:36.215 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:36.717 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:36.717 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:36.717 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1279) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:36.717 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:37.221 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:37.221 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:37.221 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1280) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:37.221 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:37.724 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:37.724 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:37.724 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1281) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:37.724 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:38.228 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:38.228 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:38.228 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1282) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:38.228 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:38.731 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:38.731 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:38.731 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1283) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:38.731 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:39.234 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:39.234 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:39.234 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1284) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:39.234 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:39.735 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:39.735 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:39.735 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1285) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:39.735 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:39.784 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:39.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 22 for partition test-0
12:35:39.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:40.237 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:40.237 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:40.237 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1286) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:40.237 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:40.740 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:40.740 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:40.740 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1287) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:40.740 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:41.243 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:41.243 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:41.243 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1288) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:41.243 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:41.746 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:41.746 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:41.747 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1289) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:41.747 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:42.248 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:42.248 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:42.248 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1290) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:42.248 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:42.524 [flink-akka.actor.default-dispatcher-114] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:35:42.524 [flink-akka.actor.default-dispatcher-116] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:35:42.524 [flink-akka.actor.default-dispatcher-114] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:35:42.524 [flink-akka.actor.default-dispatcher-116] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:35:42.524 [flink-akka.actor.default-dispatcher-114] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 621afbc6d2b245ff6afa7759e6d8da3a.
12:35:42.524 [flink-akka.actor.default-dispatcher-117] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:42.525 [flink-akka.actor.default-dispatcher-117] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received new slot report from TaskManager 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:42.525 [flink-akka.actor.default-dispatcher-117] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Received slot report from instance f2876166ab70148059ed9f2f9a72cef9.
12:35:42.752 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:42.752 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:42.752 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1291) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:42.752 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:43.255 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:43.255 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:43.255 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1292) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:43.255 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:43.757 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:43.757 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:43.758 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1293) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:43.758 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:43.913 [flink-akka.actor.default-dispatcher-117] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
12:35:43.913 [flink-akka.actor.default-dispatcher-117] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from 621afbc6d2b245ff6afa7759e6d8da3a.
12:35:43.913 [flink-akka.actor.default-dispatcher-116] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:44.260 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:44.260 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:44.260 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1294) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:44.260 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:44.763 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:44.763 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:44.763 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1295) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:44.763 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:44.784 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:44.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 22 for partition test-0
12:35:44.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:45.266 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:45.266 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:45.266 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1296) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:45.266 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:45.768 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:45.768 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:45.768 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1297) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:45.768 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:46.271 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:46.271 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:46.271 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1298) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:46.271 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:46.774 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:46.774 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:46.774 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1299) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:46.774 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:47.277 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:47.277 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:47.278 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1300) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:47.278 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:47.780 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:47.780 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:47.780 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1301) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:47.780 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:48.282 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:48.282 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:48.282 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1302) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:48.282 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:48.795 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:48.795 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:48.795 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1303) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:48.796 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:49.298 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:49.298 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:49.298 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1304) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:49.298 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:49.785 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:49.789 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 22 for partition test-0
12:35:49.789 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:49.800 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:49.800 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:49.800 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1305) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:49.800 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:50.304 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:50.304 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:50.304 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1306) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:50.304 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:50.805 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:50.805 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:50.805 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1307) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:50.805 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:51.308 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:51.308 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:51.308 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1308) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:51.308 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:51.811 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:51.811 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:51.811 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1309) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:51.812 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:52.313 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:52.313 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:52.313 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1310) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:52.313 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:52.520 [flink-akka.actor.default-dispatcher-117] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:35:52.521 [flink-akka.actor.default-dispatcher-114] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:35:52.521 [flink-akka.actor.default-dispatcher-114] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:35:52.521 [flink-akka.actor.default-dispatcher-117] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:35:52.522 [flink-akka.actor.default-dispatcher-114] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 621afbc6d2b245ff6afa7759e6d8da3a.
12:35:52.522 [flink-akka.actor.default-dispatcher-117] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:52.522 [flink-akka.actor.default-dispatcher-117] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received new slot report from TaskManager 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:52.523 [flink-akka.actor.default-dispatcher-117] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Received slot report from instance f2876166ab70148059ed9f2f9a72cef9.
12:35:52.815 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:52.815 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:52.815 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1311) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:52.815 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:53.317 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:53.317 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:53.317 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1312) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:53.317 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:53.819 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:53.819 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:53.819 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1313) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:53.819 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:53.914 [flink-akka.actor.default-dispatcher-117] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
12:35:53.914 [flink-akka.actor.default-dispatcher-114] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from 621afbc6d2b245ff6afa7759e6d8da3a.
12:35:53.917 [flink-akka.actor.default-dispatcher-114] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:35:54.322 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:54.322 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:54.322 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1314) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:54.322 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:54.785 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:54.786 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 22 for partition test-0
12:35:54.786 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:54.823 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:54.823 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:54.824 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1315) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:54.824 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:55.326 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:55.326 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:55.326 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1316) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:55.326 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:55.829 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:55.829 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:55.829 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1317) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:55.829 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:56.331 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:56.331 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:56.331 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1318) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:56.331 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:56.834 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:56.834 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:56.834 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1319) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:56.834 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:57.338 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:57.338 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:57.338 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1320) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:57.338 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:57.840 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:57.840 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:57.840 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1321) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:57.840 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:58.344 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:58.344 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:58.344 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1322) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:58.344 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:58.845 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:58.845 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:58.845 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1323) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:58.845 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:59.348 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:59.348 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:59.348 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1324) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:59.348 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:59.786 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:59.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 22 for partition test-0
12:35:59.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:35:59.850 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:35:59.850 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:35:59.850 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1325) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:35:59.850 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:00.352 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:00.352 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:00.352 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1326) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:00.352 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:00.855 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:00.855 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:00.855 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1327) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:00.855 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:01.357 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:01.357 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:01.357 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1328) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:01.357 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:01.859 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:01.859 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:01.859 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1329) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:01.859 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:02.360 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:02.360 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:02.361 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1330) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:02.361 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:02.525 [flink-akka.actor.default-dispatcher-120] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:36:02.525 [flink-akka.actor.default-dispatcher-119] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:36:02.526 [flink-akka.actor.default-dispatcher-119] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:36:02.526 [flink-akka.actor.default-dispatcher-120] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:36:02.526 [flink-akka.actor.default-dispatcher-119] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 621afbc6d2b245ff6afa7759e6d8da3a.
12:36:02.527 [flink-akka.actor.default-dispatcher-121] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:02.528 [flink-akka.actor.default-dispatcher-121] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received new slot report from TaskManager 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:02.528 [flink-akka.actor.default-dispatcher-121] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Received slot report from instance f2876166ab70148059ed9f2f9a72cef9.
12:36:02.864 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:02.864 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:02.864 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1331) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:02.864 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:03.365 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:03.365 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:03.365 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1332) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:03.365 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:03.869 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:03.869 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:03.869 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1333) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:03.869 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:03.913 [flink-akka.actor.default-dispatcher-121] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
12:36:03.913 [flink-akka.actor.default-dispatcher-121] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from 621afbc6d2b245ff6afa7759e6d8da3a.
12:36:03.915 [flink-akka.actor.default-dispatcher-121] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:04.371 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:04.371 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:04.371 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1334) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:04.371 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:04.786 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:36:04.790 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 22 for partition test-0
12:36:04.790 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=22, metadata=''}}
12:36:04.873 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:04.873 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:04.873 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1335) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:04.873 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:05.375 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:05.375 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:05.375 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1336) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:05.375 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:05.877 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:05.877 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:05.877 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1337) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:05.877 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:06.380 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:06.380 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:06.380 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1338) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:06.380 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:06.881 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:06.881 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:06.881 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1339) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:06.881 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:07.382 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:07.382 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:07.382 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1340) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:07.382 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:07.885 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:07.885 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:07.885 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1341) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:07.885 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:08.388 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:08.388 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:08.388 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1342) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:08.388 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:08.890 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:08.890 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:08.891 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1343) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:08.891 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:09.393 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:09.393 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 22 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:09.393 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1344) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:09.393 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:09.457 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 1 response partition(s)
12:36:09.457 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Fetch READ_UNCOMMITTED at offset 22 for partition test-0 returned fetch data (error=NONE, highWaterMark=26, lastStableOffset = 26, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=96)
12:36:09.458 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 26 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:09.458 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1345) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:09.458 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(test-0), toForget=(), implied=()) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
1> b
2> c
kafka:c
kafka:b
kafka:a
kafka:d
8> (a,3)
1> (b,4)
2> (c,4)
8> a
3> d
3> (d,4)
12:36:09.537 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 24] start execution
12:36:09.537 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 25] start execution
12:36:09.537 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 26] start execution
12:36:09.538 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:36:09.538 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 27] start execution
12:36:09.538 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:36:09.538 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:36:09.539 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:36:09.539 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:36:09.539 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:36:09.539 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:36:09.539 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 24] Request connection for {}->http://127.0.0.1:9200
12:36:09.539 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:36:09.539 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:36:09.539 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 26] Request connection for {}->http://127.0.0.1:9200
12:36:09.539 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 25] Request connection for {}->http://127.0.0.1:9200
12:36:09.540 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:09.540 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:09.540 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:09.540 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:36:09.540 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:09.540 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:09.540 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:09.540 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:36:09.540 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:36:09.540 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 27] Request connection for {}->http://127.0.0.1:9200
12:36:09.540 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-7][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:09.540 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-4][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:09.541 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:09.541 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-5][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:09.541 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 26] Connection allocated: CPoolProxy{http-outgoing-4 [ACTIVE]}
12:36:09.541 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 25] Connection allocated: CPoolProxy{http-outgoing-7 [ACTIVE]}
12:36:09.541 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:36:09.541 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 24] Connection allocated: CPoolProxy{http-outgoing-5 [ACTIVE]}
12:36:09.541 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:36:09.541 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:09.541 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:36:09.541 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][rw:r]: Event set [w]
12:36:09.541 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][rw:r]: Event set [w]
12:36:09.541 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [ACTIVE] Request ready
12:36:09.541 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [ACTIVE] Request ready
12:36:09.541 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-6][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:09.542 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [ACTIVE] Request ready
12:36:09.542 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 26] Attempt 1 to execute request
12:36:09.542 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 26] Target auth state: UNCHALLENGED
12:36:09.542 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 27] Connection allocated: CPoolProxy{http-outgoing-6 [ACTIVE]}
12:36:09.542 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 25] Attempt 1 to execute request
12:36:09.542 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][rw:r]: Event set [w]
12:36:09.542 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:36:09.542 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 26] Proxy auth state: UNCHALLENGED
12:36:09.542 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 25] Target auth state: UNCHALLENGED
12:36:09.542 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 24] Attempt 1 to execute request
12:36:09.542 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:36:09.542 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 24] Target auth state: UNCHALLENGED
12:36:09.542 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [ACTIVE] Request ready
12:36:09.543 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 >> POST /_bulk?timeout=1m HTTP/1.1
12:36:09.542 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][rw:r]: Event set [w]
12:36:09.543 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 >> Content-Length: 102
12:36:09.543 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 >> Content-Type: application/json
12:36:09.543 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 >> Host: 127.0.0.1:9200
12:36:09.542 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 25] Proxy auth state: UNCHALLENGED
12:36:09.543 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 27] Attempt 1 to execute request
12:36:09.543 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 27] Target auth state: UNCHALLENGED
12:36:09.543 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 24] Proxy auth state: UNCHALLENGED
12:36:09.543 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 27] Proxy auth state: UNCHALLENGED
12:36:09.543 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 >> Connection: Keep-Alive
12:36:09.543 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:36:09.543 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:36:09.543 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 >> POST /_bulk?timeout=1m HTTP/1.1
12:36:09.543 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:36:09.543 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 >> POST /_bulk?timeout=1m HTTP/1.1
12:36:09.543 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 >> Content-Length: 102
12:36:09.544 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 >> Content-Type: application/json
12:36:09.543 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:36:09.543 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 >> Content-Length: 102
12:36:09.544 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 >> Content-Type: application/json
12:36:09.544 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 >> Host: 127.0.0.1:9200
12:36:09.544 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 >> Connection: Keep-Alive
12:36:09.544 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 >> POST /_bulk?timeout=1m HTTP/1.1
12:36:09.544 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:36:09.544 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 >> Host: 127.0.0.1:9200
12:36:09.544 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [ACTIVE] Output ready
12:36:09.544 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 >> Connection: Keep-Alive
12:36:09.544 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:36:09.544 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:36:09.544 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 >> Content-Length: 102
12:36:09.544 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 >> Content-Type: application/json
12:36:09.544 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 26] produce content
12:36:09.544 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 >> Host: 127.0.0.1:9200
12:36:09.544 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 >> Connection: Keep-Alive
12:36:09.544 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:36:09.545 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 26] Request completed
12:36:09.545 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [ACTIVE] [content length: 102; pos: 102; completed: true]
12:36:09.545 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:36:09.545 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [ACTIVE] Output ready
12:36:09.545 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 25] produce content
12:36:09.545 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:36:09.545 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [ACTIVE] Output ready
12:36:09.545 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 27] produce content
12:36:09.545 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 25] Request completed
12:36:09.545 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][rw:w]: 292 bytes written
12:36:09.545 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:36:09.545 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [ACTIVE] Output ready
12:36:09.545 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 24] produce content
12:36:09.545 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [ACTIVE] [content length: 102; pos: 102; completed: true]
12:36:09.545 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 27] Request completed
12:36:09.546 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 24] Request completed
12:36:09.546 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [ACTIVE] [content length: 102; pos: 102; completed: true]
12:36:09.546 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [ACTIVE] [content length: 102; pos: 102; completed: true]
12:36:09.546 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][rw:w]: 292 bytes written
12:36:09.546 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][rw:w]: 292 bytes written
12:36:09.546 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:36:09.546 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][rw:w]: 292 bytes written
12:36:09.546 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:36:09.546 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:36:09.546 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "Content-Length: 102[\r][\n]"
12:36:09.547 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "Content-Type: application/json[\r][\n]"
12:36:09.545 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:36:09.547 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "Host: 127.0.0.1:9200[\r][\n]"
12:36:09.547 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "Connection: Keep-Alive[\r][\n]"
12:36:09.546 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "Content-Length: 102[\r][\n]"
12:36:09.547 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "Content-Length: 102[\r][\n]"
12:36:09.547 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:36:09.547 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "Content-Type: application/json[\r][\n]"
12:36:09.547 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "Content-Type: application/json[\r][\n]"
12:36:09.547 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "Host: 127.0.0.1:9200[\r][\n]"
12:36:09.547 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "Host: 127.0.0.1:9200[\r][\n]"
12:36:09.547 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "Connection: Keep-Alive[\r][\n]"
12:36:09.548 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "Connection: Keep-Alive[\r][\n]"
12:36:09.547 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "Content-Length: 102[\r][\n]"
12:36:09.548 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:36:09.548 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "[\r][\n]"
12:36:09.548 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "Content-Type: application/json[\r][\n]"
12:36:09.547 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "[\r][\n]"
12:36:09.548 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:36:09.548 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "Host: 127.0.0.1:9200[\r][\n]"
12:36:09.548 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "[\r][\n]"
12:36:09.548 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
12:36:09.548 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"d"}}[\n]"
12:36:09.548 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"a"}}[\n]"
12:36:09.548 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"b"}}[\n]"
12:36:09.548 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:36:09.548 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "[\r][\n]"
12:36:09.548 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "{"doc_as_upsert":true,"doc":{"status":4}}[\n]"
12:36:09.548 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "{"doc_as_upsert":true,"doc":{"status":3}}[\n]"
12:36:09.549 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "{"doc_as_upsert":true,"doc":{"status":4}}[\n]"
12:36:09.549 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [ACTIVE] Request ready
12:36:09.549 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"c"}}[\n]"
12:36:09.549 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [ACTIVE] Request ready
12:36:09.549 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [ACTIVE] Request ready
12:36:09.549 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "{"doc_as_upsert":true,"doc":{"status":4}}[\n]"
12:36:09.549 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:36:09.549 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:36:09.549 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:36:09.549 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [ACTIVE] Request ready
12:36:09.550 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:36:09.787 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=26, metadata=''}}
12:36:09.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 26 for partition test-0
12:36:09.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=26, metadata=''}}
12:36:09.960 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:09.960 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 26 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:09.960 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1346) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:09.960 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:10.097 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][r:r]: 417 bytes read
12:36:10.097 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][r:r]: 417 bytes read
12:36:10.097 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 << "HTTP/1.1 200 OK[\r][\n]"
12:36:10.097 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 << "HTTP/1.1 200 OK[\r][\n]"
12:36:10.098 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 << "Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."[\r][\n]"
12:36:10.098 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 << "Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."[\r][\n]"
12:36:10.098 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 << "content-type: application/json; charset=UTF-8[\r][\n]"
12:36:10.098 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 << "content-type: application/json; charset=UTF-8[\r][\n]"
12:36:10.098 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 << "content-length: 221[\r][\n]"
12:36:10.098 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 << "content-length: 221[\r][\n]"
12:36:10.098 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 << "[\r][\n]"
12:36:10.098 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 << "[\r][\n]"
12:36:10.098 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 << "{"took":548,"errors":false,"items":[{"update":{"_index":"test_index","_type":"_doc","_id":"d","_version":2,"result":"updated","_shards":{"total":2,"successful":2,"failed":0},"_seq_no":12,"_primary_term":1,"status":200}}]}"
12:36:10.098 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 << "{"took":550,"errors":false,"items":[{"update":{"_index":"test_index","_type":"_doc","_id":"b","_version":2,"result":"updated","_shards":{"total":2,"successful":2,"failed":0},"_seq_no":13,"_primary_term":1,"status":200}}]}"
12:36:10.099 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 << HTTP/1.1 200 OK
12:36:10.099 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 << HTTP/1.1 200 OK
12:36:10.099 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 << Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."
12:36:10.099 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 << content-type: application/json; charset=UTF-8
12:36:10.099 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 << content-length: 221
12:36:10.099 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 << Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."
12:36:10.099 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [ACTIVE(221)] Response received
12:36:10.099 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 << content-type: application/json; charset=UTF-8
12:36:10.099 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 << content-length: 221
12:36:10.099 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [ACTIVE(221)] Response received
12:36:10.100 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 27] Response received HTTP/1.1 200 OK
12:36:10.100 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 25] Response received HTTP/1.1 200 OK
12:36:10.100 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [ACTIVE(221)] Input ready
12:36:10.100 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 27] Consume content
12:36:10.100 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [ACTIVE(221)] Input ready
12:36:10.100 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 25] Consume content
12:36:10.100 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 27] Connection can be kept alive indefinitely
12:36:10.100 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 25] Connection can be kept alive indefinitely
12:36:10.100 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 27] Response processed
12:36:10.100 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 27] releasing connection
12:36:10.100 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 25] Response processed
12:36:10.100 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 25] releasing connection
12:36:10.100 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][r:r]: Remove attribute http.nio.exchange-handler
12:36:10.100 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][r:r]: Remove attribute http.nio.exchange-handler
12:36:10.101 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-6][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.101 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-7][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.101 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection [id: http-outgoing-7][route: {}->http://127.0.0.1:9200] can be kept alive indefinitely
12:36:10.101 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection [id: http-outgoing-6][route: {}->http://127.0.0.1:9200] can be kept alive indefinitely
12:36:10.101 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:10.101 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:10.101 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-7][route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.102 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-6][route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.102 [I/O dispatcher 33] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned [HTTP/1.1 200 OK]
12:36:10.102 [I/O dispatcher 25] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned [HTTP/1.1 200 OK]
12:36:10.102 [I/O dispatcher 33] WARN org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."]
12:36:10.102 [I/O dispatcher 25] WARN org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."]
12:36:10.103 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [ACTIVE] [content length: 221; pos: 221; completed: true]
12:36:10.103 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [ACTIVE] [content length: 221; pos: 221; completed: true]
12:36:10.272 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][r:r]: 417 bytes read
12:36:10.272 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 << "HTTP/1.1 200 OK[\r][\n]"
12:36:10.272 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 << "Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."[\r][\n]"
12:36:10.272 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][r:r]: 417 bytes read
12:36:10.272 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 << "content-type: application/json; charset=UTF-8[\r][\n]"
12:36:10.272 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 << "content-length: 221[\r][\n]"
12:36:10.272 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 << "[\r][\n]"
12:36:10.272 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 << "HTTP/1.1 200 OK[\r][\n]"
12:36:10.272 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 << "Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."[\r][\n]"
12:36:10.272 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 << "{"took":723,"errors":false,"items":[{"update":{"_index":"test_index","_type":"_doc","_id":"a","_version":2,"result":"updated","_shards":{"total":2,"successful":2,"failed":0},"_seq_no":11,"_primary_term":1,"status":200}}]}"
12:36:10.272 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 << "content-type: application/json; charset=UTF-8[\r][\n]"
12:36:10.272 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 << "content-length: 221[\r][\n]"
12:36:10.272 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 << "[\r][\n]"
12:36:10.272 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 << "{"took":725,"errors":false,"items":[{"update":{"_index":"test_index","_type":"_doc","_id":"c","_version":2,"result":"updated","_shards":{"total":2,"successful":2,"failed":0},"_seq_no":10,"_primary_term":1,"status":200}}]}"
12:36:10.272 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 << HTTP/1.1 200 OK
12:36:10.272 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 << Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."
12:36:10.272 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 << content-type: application/json; charset=UTF-8
12:36:10.272 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 << content-length: 221
12:36:10.272 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [ACTIVE(221)] Response received
12:36:10.272 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 24] Response received HTTP/1.1 200 OK
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 << HTTP/1.1 200 OK
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 << Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 << content-type: application/json; charset=UTF-8
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 << content-length: 221
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [ACTIVE(221)] Response received
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 26] Response received HTTP/1.1 200 OK
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [ACTIVE(221)] Input ready
12:36:10.273 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [ACTIVE(221)] Input ready
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 26] Consume content
12:36:10.273 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 24] Consume content
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 26] Connection can be kept alive indefinitely
12:36:10.273 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 24] Connection can be kept alive indefinitely
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 26] Response processed
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 26] releasing connection
12:36:10.273 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 24] Response processed
12:36:10.273 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 24] releasing connection
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][r:r]: Remove attribute http.nio.exchange-handler
12:36:10.273 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][r:r]: Remove attribute http.nio.exchange-handler
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-4][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.273 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-5][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection [id: http-outgoing-4][route: {}->http://127.0.0.1:9200] can be kept alive indefinitely
12:36:10.273 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection [id: http-outgoing-5][route: {}->http://127.0.0.1:9200] can be kept alive indefinitely
12:36:10.273 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:10.273 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-5][route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.273 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-4][route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.273 [I/O dispatcher 17] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned [HTTP/1.1 200 OK]
12:36:10.273 [I/O dispatcher 41] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned [HTTP/1.1 200 OK]
12:36:10.274 [I/O dispatcher 41] WARN org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."]
12:36:10.274 [I/O dispatcher 17] WARN org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."]
12:36:10.274 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [ACTIVE] [content length: 221; pos: 221; completed: true]
12:36:10.274 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [ACTIVE] [content length: 221; pos: 221; completed: true]
12:36:10.463 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:10.463 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 26 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:10.463 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1347) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:10.463 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:10.477 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 1 response partition(s)
12:36:10.477 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Fetch READ_UNCOMMITTED at offset 26 for partition test-0 returned fetch data (error=NONE, highWaterMark=30, lastStableOffset = 30, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=96)
12:36:10.478 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 30 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:10.479 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1348) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:10.479 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(test-0), toForget=(), implied=()) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
kafka:e
kafka:d
7> d
kafka:e
6> e
5> e
4> e
kafka:e
6> (e,4)
7> (d,4)
4> (e,4)
5> (e,4)
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 29] start execution
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 28] start execution
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 31] start execution
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 30] start execution
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 29] Request connection for {}->http://127.0.0.1:9200
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 28] Request connection for {}->http://127.0.0.1:9200
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 31] Request connection for {}->http://127.0.0.1:9200
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 30] Request connection for {}->http://127.0.0.1:9200
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:10.536 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-3 127.0.0.1:53913<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:10.537 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-2][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.537 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-0][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.537 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-1][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.537 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 29] Connection allocated: CPoolProxy{http-outgoing-2 [ACTIVE]}
12:36:10.537 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 28] Connection allocated: CPoolProxy{http-outgoing-0 [ACTIVE]}
12:36:10.537 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-3][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.537 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:36:10.537 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 31] Connection allocated: CPoolProxy{http-outgoing-1 [ACTIVE]}
12:36:10.537 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:36:10.538 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 30] Connection allocated: CPoolProxy{http-outgoing-3 [ACTIVE]}
12:36:10.538 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:36:10.538 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][rw:r]: Event set [w]
12:36:10.538 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-3 127.0.0.1:53913<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:36:10.538 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [ACTIVE] Request ready
12:36:10.538 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][rw:r]: Event set [w]
12:36:10.538 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][rw:r]: Event set [w]
12:36:10.538 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 29] Attempt 1 to execute request
12:36:10.538 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-0 [ACTIVE] Request ready
12:36:10.538 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [ACTIVE] Request ready
12:36:10.538 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 29] Target auth state: UNCHALLENGED
12:36:10.538 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-3 127.0.0.1:53913<->127.0.0.1:9200[ACTIVE][rw:r]: Event set [w]
12:36:10.538 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 31] Attempt 1 to execute request
12:36:10.538 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-3 [ACTIVE] Request ready
12:36:10.538 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 31] Target auth state: UNCHALLENGED
12:36:10.538 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 28] Attempt 1 to execute request
12:36:10.538 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 30] Attempt 1 to execute request
12:36:10.538 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 29] Proxy auth state: UNCHALLENGED
12:36:10.538 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 28] Target auth state: UNCHALLENGED
12:36:10.538 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 31] Proxy auth state: UNCHALLENGED
12:36:10.538 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 30] Target auth state: UNCHALLENGED
12:36:10.538 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:36:10.538 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:36:10.538 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 28] Proxy auth state: UNCHALLENGED
12:36:10.538 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 30] Proxy auth state: UNCHALLENGED
12:36:10.538 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 >> POST /_bulk?timeout=1m HTTP/1.1
12:36:10.538 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 >> POST /_bulk?timeout=1m HTTP/1.1
12:36:10.538 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-3 127.0.0.1:53913<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:36:10.538 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 >> Content-Length: 102
12:36:10.538 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 >> Content-Type: application/json
12:36:10.538 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 >> Content-Length: 102
12:36:10.538 [I/O dispatcher 1] DEBUG org.apache.http.headers - http-outgoing-3 >> POST /_bulk?timeout=1m HTTP/1.1
12:36:10.538 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:36:10.538 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 >> Host: 127.0.0.1:9200
12:36:10.539 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 >> Connection: Keep-Alive
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 >> POST /_bulk?timeout=1m HTTP/1.1
12:36:10.539 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:36:10.538 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 >> Content-Type: application/json
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 >> Content-Length: 102
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 >> Content-Type: application/json
12:36:10.539 [I/O dispatcher 1] DEBUG org.apache.http.headers - http-outgoing-3 >> Content-Length: 102
12:36:10.539 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 >> Host: 127.0.0.1:9200
12:36:10.539 [I/O dispatcher 1] DEBUG org.apache.http.headers - http-outgoing-3 >> Content-Type: application/json
12:36:10.539 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 >> Connection: Keep-Alive
12:36:10.539 [I/O dispatcher 1] DEBUG org.apache.http.headers - http-outgoing-3 >> Host: 127.0.0.1:9200
12:36:10.539 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 >> Host: 127.0.0.1:9200
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 >> Connection: Keep-Alive
12:36:10.539 [I/O dispatcher 1] DEBUG org.apache.http.headers - http-outgoing-3 >> Connection: Keep-Alive
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:36:10.539 [I/O dispatcher 1] DEBUG org.apache.http.headers - http-outgoing-3 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:36:10.539 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:36:10.539 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [ACTIVE] Output ready
12:36:10.539 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 29] produce content
12:36:10.539 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:36:10.539 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 29] Request completed
12:36:10.539 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [ACTIVE] Output ready
12:36:10.539 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 31] produce content
12:36:10.539 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [ACTIVE] [content length: 102; pos: 102; completed: true]
12:36:10.539 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 31] Request completed
12:36:10.539 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-3 127.0.0.1:53913<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:36:10.539 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-3 [ACTIVE] Output ready
12:36:10.539 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [ACTIVE] [content length: 102; pos: 102; completed: true]
12:36:10.539 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 30] produce content
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-0 [ACTIVE] Output ready
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 28] produce content
12:36:10.539 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 30] Request completed
12:36:10.539 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-3 [ACTIVE] [content length: 102; pos: 102; completed: true]
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 28] Request completed
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-0 [ACTIVE] [content length: 102; pos: 102; completed: true]
12:36:10.539 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][rw:w]: 292 bytes written
12:36:10.539 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-3 127.0.0.1:53913<->127.0.0.1:9200[ACTIVE][rw:w]: 292 bytes written
12:36:10.539 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][rw:w]: 292 bytes written
12:36:10.539 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][rw:w]: 292 bytes written
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "Content-Length: 102[\r][\n]"
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "Content-Type: application/json[\r][\n]"
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "Host: 127.0.0.1:9200[\r][\n]"
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "[\r][\n]"
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"e"}}[\n]"
12:36:10.539 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "{"doc_as_upsert":true,"doc":{"status":4}}[\n]"
12:36:10.539 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "Content-Length: 102[\r][\n]"
12:36:10.540 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "Content-Type: application/json[\r][\n]"
12:36:10.540 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "Host: 127.0.0.1:9200[\r][\n]"
12:36:10.540 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
12:36:10.540 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:36:10.540 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "[\r][\n]"
12:36:10.540 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-0 [ACTIVE] Request ready
12:36:10.540 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"e"}}[\n]"
12:36:10.540 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:36:10.540 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "{"doc_as_upsert":true,"doc":{"status":4}}[\n]"
12:36:10.539 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:36:10.540 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 >> "Content-Length: 102[\r][\n]"
12:36:10.540 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [ACTIVE] Request ready
12:36:10.540 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 >> "Content-Type: application/json[\r][\n]"
12:36:10.540 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 >> "Host: 127.0.0.1:9200[\r][\n]"
12:36:10.540 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:36:10.540 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 >> "Connection: Keep-Alive[\r][\n]"
12:36:10.539 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:36:10.540 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:36:10.540 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 >> "[\r][\n]"
12:36:10.540 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "Content-Length: 102[\r][\n]"
12:36:10.540 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"e"}}[\n]"
12:36:10.540 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "Content-Type: application/json[\r][\n]"
12:36:10.540 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 >> "{"doc_as_upsert":true,"doc":{"status":4}}[\n]"
12:36:10.540 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "Host: 127.0.0.1:9200[\r][\n]"
12:36:10.540 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "Connection: Keep-Alive[\r][\n]"
12:36:10.540 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-3 [ACTIVE] Request ready
12:36:10.540 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-3 127.0.0.1:53913<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:36:10.540 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:36:10.540 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "[\r][\n]"
12:36:10.540 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"d"}}[\n]"
12:36:10.541 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 >> "{"doc_as_upsert":true,"doc":{"status":4}}[\n]"
12:36:10.541 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [ACTIVE] Request ready
12:36:10.541 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:36:10.545 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-3 127.0.0.1:53913<->127.0.0.1:9200[ACTIVE][r:r]: 552 bytes read
12:36:10.545 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 << "HTTP/1.1 200 OK[\r][\n]"
12:36:10.545 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 << "Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."[\r][\n]"
12:36:10.545 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 << "content-type: application/json; charset=UTF-8[\r][\n]"
12:36:10.545 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 << "content-length: 356[\r][\n]"
12:36:10.545 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 << "[\r][\n]"
12:36:10.545 [I/O dispatcher 1] DEBUG org.apache.http.wire - http-outgoing-3 << "{"took":4,"errors":true,"items":[{"update":{"_index":"test_index","_type":"_doc","_id":"e","status":409,"error":{"type":"version_conflict_engine_exception","reason":"[e]: version conflict, required seqNo [8], primary term [1]. current document has seqNo [14] and primary term [1]","index_uuid":"m3mCLiSmQbugO4TXupHgrw","shard":"0","index":"test_index"}}}]}"
12:36:10.545 [I/O dispatcher 1] DEBUG org.apache.http.headers - http-outgoing-3 << HTTP/1.1 200 OK
12:36:10.545 [I/O dispatcher 1] DEBUG org.apache.http.headers - http-outgoing-3 << Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."
12:36:10.545 [I/O dispatcher 1] DEBUG org.apache.http.headers - http-outgoing-3 << content-type: application/json; charset=UTF-8
12:36:10.545 [I/O dispatcher 1] DEBUG org.apache.http.headers - http-outgoing-3 << content-length: 356
12:36:10.545 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-3 [ACTIVE(356)] Response received
12:36:10.546 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 30] Response received HTTP/1.1 200 OK
12:36:10.546 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-3 [ACTIVE(356)] Input ready
12:36:10.546 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 30] Consume content
12:36:10.546 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 30] Connection can be kept alive indefinitely
12:36:10.546 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 30] Response processed
12:36:10.546 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 30] releasing connection
12:36:10.546 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-3 127.0.0.1:53913<->127.0.0.1:9200[ACTIVE][r:r]: Remove attribute http.nio.exchange-handler
12:36:10.547 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-3][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.547 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection [id: http-outgoing-3][route: {}->http://127.0.0.1:9200] can be kept alive indefinitely
12:36:10.547 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-3 127.0.0.1:53913<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:10.547 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-3][route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.547 [I/O dispatcher 1] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned [HTTP/1.1 200 OK]
12:36:10.548 [I/O dispatcher 1] WARN org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."]
12:36:10.637 [I/O dispatcher 1] ERROR org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase - Failed Elasticsearch item request: [test_index/m3mCLiSmQbugO4TXupHgrw][[test_index][0]] ElasticsearchException[Elasticsearch exception [type=version_conflict_engine_exception, reason=[e]: version conflict, required seqNo [8], primary term [1]. current document has seqNo [14] and primary term [1]]]
org.elasticsearch.ElasticsearchException: Elasticsearch exception [type=version_conflict_engine_exception, reason=[e]: version conflict, required seqNo [8], primary term [1]. current document has seqNo [14] and primary term [1]]
	at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:509)
	at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:420)
	at org.elasticsearch.action.bulk.BulkItemResponse.fromXContent(BulkItemResponse.java:135)
	at org.elasticsearch.action.bulk.BulkResponse.fromXContent(BulkResponse.java:198)
	at org.elasticsearch.client.RestHighLevelClient.parseEntity(RestHighLevelClient.java:1406)
	at org.elasticsearch.client.RestHighLevelClient.lambda$performRequestAsyncAndParseEntity$10(RestHighLevelClient.java:1284)
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:1334)
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:836)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:538)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:529)
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122)
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338)
	at org.apache.http.impl.nio.client.InternalRequestExecutor.inputReady(InternalRequestExecutor.java:83)
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591)
	at java.base/java.lang.Thread.run(Thread.java:834)
12:36:10.638 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-3 [ACTIVE] [content length: 356; pos: 356; completed: true]
12:36:10.741 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][r:r]: 383 bytes read
12:36:10.741 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 << "HTTP/1.1 200 OK[\r][\n]"
12:36:10.741 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 << "Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."[\r][\n]"
12:36:10.741 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 << "content-type: application/json; charset=UTF-8[\r][\n]"
12:36:10.741 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 << "content-length: 187[\r][\n]"
12:36:10.741 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 << "[\r][\n]"
12:36:10.742 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 << "{"took":200,"errors":false,"items":[{"update":{"_index":"test_index","_type":"_doc","_id":"e","_version":4,"result":"noop","_shards":{"total":2,"successful":2,"failed":0},"status":200}}]}"
12:36:10.742 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 << HTTP/1.1 200 OK
12:36:10.742 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 << Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."
12:36:10.742 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 << content-type: application/json; charset=UTF-8
12:36:10.742 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 << content-length: 187
12:36:10.742 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-0 [ACTIVE(187)] Response received
12:36:10.742 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 28] Response received HTTP/1.1 200 OK
12:36:10.742 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-0 [ACTIVE(187)] Input ready
12:36:10.742 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 28] Consume content
12:36:10.743 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 28] Connection can be kept alive indefinitely
12:36:10.743 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 28] Response processed
12:36:10.743 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 28] releasing connection
12:36:10.743 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][r:r]: Remove attribute http.nio.exchange-handler
12:36:10.743 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-0][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.743 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection [id: http-outgoing-0][route: {}->http://127.0.0.1:9200] can be kept alive indefinitely
12:36:10.743 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:10.743 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-0][route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.743 [I/O dispatcher 57] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned [HTTP/1.1 200 OK]
12:36:10.743 [I/O dispatcher 57] WARN org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."]
12:36:10.744 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-0 [ACTIVE] [content length: 187; pos: 187; completed: true]
12:36:10.812 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][r:r]: 383 bytes read
12:36:10.812 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 << "HTTP/1.1 200 OK[\r][\n]"
12:36:10.812 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 << "Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."[\r][\n]"
12:36:10.812 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 << "content-type: application/json; charset=UTF-8[\r][\n]"
12:36:10.812 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 << "content-length: 187[\r][\n]"
12:36:10.812 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 << "[\r][\n]"
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.wire - http-outgoing-1 << "{"took":272,"errors":false,"items":[{"update":{"_index":"test_index","_type":"_doc","_id":"d","_version":2,"result":"noop","_shards":{"total":2,"successful":2,"failed":0},"status":200}}]}"
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 << HTTP/1.1 200 OK
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 << Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 << content-type: application/json; charset=UTF-8
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.headers - http-outgoing-1 << content-length: 187
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [ACTIVE(187)] Response received
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 31] Response received HTTP/1.1 200 OK
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [ACTIVE(187)] Input ready
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 31] Consume content
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 31] Connection can be kept alive indefinitely
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 31] Response processed
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 31] releasing connection
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][r:r]: Remove attribute http.nio.exchange-handler
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-1][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.813 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection [id: http-outgoing-1][route: {}->http://127.0.0.1:9200] can be kept alive indefinitely
12:36:10.814 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:10.814 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-1][route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:10.814 [I/O dispatcher 49] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned [HTTP/1.1 200 OK]
12:36:10.814 [I/O dispatcher 49] WARN org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."]
12:36:10.814 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [ACTIVE] [content length: 187; pos: 187; completed: true]
12:36:10.980 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:10.980 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 30 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:10.980 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1349) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:10.980 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:11.381 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][r:r]: 417 bytes read
12:36:11.382 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 << "HTTP/1.1 200 OK[\r][\n]"
12:36:11.382 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 << "Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."[\r][\n]"
12:36:11.382 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 << "content-type: application/json; charset=UTF-8[\r][\n]"
12:36:11.382 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 << "content-length: 221[\r][\n]"
12:36:11.382 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 << "[\r][\n]"
12:36:11.383 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 << "{"took":841,"errors":false,"items":[{"update":{"_index":"test_index","_type":"_doc","_id":"e","_version":4,"result":"updated","_shards":{"total":2,"successful":2,"failed":0},"_seq_no":14,"_primary_term":1,"status":200}}]}"
12:36:11.383 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 << HTTP/1.1 200 OK
12:36:11.383 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 << Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."
12:36:11.384 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 << content-type: application/json; charset=UTF-8
12:36:11.384 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 << content-length: 221
12:36:11.384 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [ACTIVE(221)] Response received
12:36:11.384 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 29] Response received HTTP/1.1 200 OK
12:36:11.384 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [ACTIVE(221)] Input ready
12:36:11.384 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 29] Consume content
12:36:11.385 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 29] Connection can be kept alive indefinitely
12:36:11.385 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 29] Response processed
12:36:11.385 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 29] releasing connection
12:36:11.385 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][r:r]: Remove attribute http.nio.exchange-handler
12:36:11.385 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-2][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:11.385 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection [id: http-outgoing-2][route: {}->http://127.0.0.1:9200] can be kept alive indefinitely
12:36:11.385 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:11.385 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-2][route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:11.386 [I/O dispatcher 9] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned [HTTP/1.1 200 OK]
12:36:11.386 [I/O dispatcher 9] WARN org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."]
12:36:11.387 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [ACTIVE] [content length: 221; pos: 221; completed: true]
12:36:11.483 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:11.483 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 30 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:11.483 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1350) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:11.483 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:11.539 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 1 response partition(s)
12:36:11.539 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Fetch READ_UNCOMMITTED at offset 30 for partition test-0 returned fetch data (error=NONE, highWaterMark=33, lastStableOffset = 33, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=87)
12:36:11.540 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:11.540 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1351) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:11.540 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(test-0), toForget=(), implied=()) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
2> d
kafka:d
kafka:d
8> d
kafka:d
1> d
2> (d,5)
1> (d,5)
8> (d,4)
12:36:11.644 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 32] start execution
12:36:11.645 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 33] start execution
12:36:11.645 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:36:11.646 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 34] start execution
12:36:11.646 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:36:11.646 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:36:11.646 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:36:11.646 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 32] Request connection for {}->http://127.0.0.1:9200
12:36:11.646 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:11.646 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:36:11.647 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:36:11.647 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 33] Request connection for {}->http://127.0.0.1:9200
12:36:11.647 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:11.647 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:11.647 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:36:11.647 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:11.647 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-4][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:11.648 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:36:11.648 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-7][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:11.648 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 32] Connection allocated: CPoolProxy{http-outgoing-4 [ACTIVE]}
12:36:11.648 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:36:11.648 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 34] Request connection for {}->http://127.0.0.1:9200
12:36:11.648 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 33] Connection allocated: CPoolProxy{http-outgoing-7 [ACTIVE]}
12:36:11.648 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:36:11.648 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:36:11.648 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:11.648 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][rw:r]: Event set [w]
12:36:11.649 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:11.649 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][rw:r]: Event set [w]
12:36:11.649 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [ACTIVE] Request ready
12:36:11.649 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [ACTIVE] Request ready
12:36:11.649 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 32] Attempt 1 to execute request
12:36:11.649 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 33] Attempt 1 to execute request
12:36:11.649 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-5][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:11.649 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 33] Target auth state: UNCHALLENGED
12:36:11.649 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 32] Target auth state: UNCHALLENGED
12:36:11.649 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 33] Proxy auth state: UNCHALLENGED
12:36:11.649 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 32] Proxy auth state: UNCHALLENGED
12:36:11.649 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 34] Connection allocated: CPoolProxy{http-outgoing-5 [ACTIVE]}
12:36:11.649 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:36:11.650 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:36:11.650 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:36:11.650 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 >> POST /_bulk?timeout=1m HTTP/1.1
12:36:11.650 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 >> POST /_bulk?timeout=1m HTTP/1.1
12:36:11.650 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 >> Content-Length: 102
12:36:11.650 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 >> Content-Length: 102
12:36:11.650 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 >> Content-Type: application/json
12:36:11.650 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 >> Content-Type: application/json
12:36:11.650 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 >> Host: 127.0.0.1:9200
12:36:11.650 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][rw:r]: Event set [w]
12:36:11.650 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 >> Host: 127.0.0.1:9200
12:36:11.650 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 >> Connection: Keep-Alive
12:36:11.650 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [ACTIVE] Request ready
12:36:11.650 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 >> Connection: Keep-Alive
12:36:11.650 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:36:11.651 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:36:11.651 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 34] Attempt 1 to execute request
12:36:11.651 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 34] Target auth state: UNCHALLENGED
12:36:11.651 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 34] Proxy auth state: UNCHALLENGED
12:36:11.651 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:36:11.651 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 >> POST /_bulk?timeout=1m HTTP/1.1
12:36:11.651 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:36:11.651 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 >> Content-Length: 102
12:36:11.651 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [ACTIVE] Output ready
12:36:11.651 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 >> Content-Type: application/json
12:36:11.651 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:36:11.651 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 >> Host: 127.0.0.1:9200
12:36:11.651 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [ACTIVE] Output ready
12:36:11.651 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 32] produce content
12:36:11.651 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 >> Connection: Keep-Alive
12:36:11.651 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 33] produce content
12:36:11.651 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:36:11.651 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 32] Request completed
12:36:11.651 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [ACTIVE] [content length: 102; pos: 102; completed: true]
12:36:11.652 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 33] Request completed
12:36:11.652 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [ACTIVE] [content length: 102; pos: 102; completed: true]
12:36:11.652 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:36:11.652 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][rw:w]: 292 bytes written
12:36:11.652 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [ACTIVE] Output ready
12:36:11.652 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 34] produce content
12:36:11.652 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:36:11.652 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][rw:w]: 292 bytes written
12:36:11.652 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 34] Request completed
12:36:11.652 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "Content-Length: 102[\r][\n]"
12:36:11.652 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [ACTIVE] [content length: 102; pos: 102; completed: true]
12:36:11.652 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:36:11.652 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "Content-Type: application/json[\r][\n]"
12:36:11.652 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "Content-Length: 102[\r][\n]"
12:36:11.652 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "Host: 127.0.0.1:9200[\r][\n]"
12:36:11.652 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "Connection: Keep-Alive[\r][\n]"
12:36:11.652 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "Content-Type: application/json[\r][\n]"
12:36:11.652 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][rw:w]: 292 bytes written
12:36:11.652 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:36:11.652 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "Host: 127.0.0.1:9200[\r][\n]"
12:36:11.652 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:36:11.652 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "[\r][\n]"
12:36:11.652 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "Content-Length: 102[\r][\n]"
12:36:11.652 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "Connection: Keep-Alive[\r][\n]"
12:36:11.653 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"d"}}[\n]"
12:36:11.653 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "Content-Type: application/json[\r][\n]"
12:36:11.653 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:36:11.653 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 >> "{"doc_as_upsert":true,"doc":{"status":5}}[\n]"
12:36:11.653 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "[\r][\n]"
12:36:11.653 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "Host: 127.0.0.1:9200[\r][\n]"
12:36:11.653 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "Connection: Keep-Alive[\r][\n]"
12:36:11.653 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [ACTIVE] Request ready
12:36:11.653 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"d"}}[\n]"
12:36:11.653 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 >> "{"doc_as_upsert":true,"doc":{"status":5}}[\n]"
12:36:11.653 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:36:11.653 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:36:11.653 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "[\r][\n]"
12:36:11.653 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [ACTIVE] Request ready
12:36:11.653 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:36:11.653 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"d"}}[\n]"
12:36:11.653 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 >> "{"doc_as_upsert":true,"doc":{"status":4}}[\n]"
12:36:11.654 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [ACTIVE] Request ready
12:36:11.654 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:36:11.656 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][r:r]: 381 bytes read
12:36:11.656 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 << "HTTP/1.1 200 OK[\r][\n]"
12:36:11.656 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 << "Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."[\r][\n]"
12:36:11.657 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 << "content-type: application/json; charset=UTF-8[\r][\n]"
12:36:11.657 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 << "content-length: 185[\r][\n]"
12:36:11.657 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 << "[\r][\n]"
12:36:11.657 [I/O dispatcher 17] DEBUG org.apache.http.wire - http-outgoing-5 << "{"took":3,"errors":false,"items":[{"update":{"_index":"test_index","_type":"_doc","_id":"d","_version":2,"result":"noop","_shards":{"total":2,"successful":2,"failed":0},"status":200}}]}"
12:36:11.658 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 << HTTP/1.1 200 OK
12:36:11.658 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 << Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."
12:36:11.658 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 << content-type: application/json; charset=UTF-8
12:36:11.658 [I/O dispatcher 17] DEBUG org.apache.http.headers - http-outgoing-5 << content-length: 185
12:36:11.658 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [ACTIVE(185)] Response received
12:36:11.658 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 34] Response received HTTP/1.1 200 OK
12:36:11.658 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [ACTIVE(185)] Input ready
12:36:11.658 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 34] Consume content
12:36:11.659 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 34] Connection can be kept alive indefinitely
12:36:11.659 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 34] Response processed
12:36:11.659 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 34] releasing connection
12:36:11.659 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][r:r]: Remove attribute http.nio.exchange-handler
12:36:11.659 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-5][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:11.660 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection [id: http-outgoing-5][route: {}->http://127.0.0.1:9200] can be kept alive indefinitely
12:36:11.660 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:11.660 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-5][route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:11.660 [I/O dispatcher 17] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned [HTTP/1.1 200 OK]
12:36:11.660 [I/O dispatcher 17] WARN org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."]
12:36:11.661 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][r:r]: 553 bytes read
12:36:11.661 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 << "HTTP/1.1 200 OK[\r][\n]"
12:36:11.661 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 << "Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."[\r][\n]"
12:36:11.661 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 << "content-type: application/json; charset=UTF-8[\r][\n]"
12:36:11.661 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 << "content-length: 357[\r][\n]"
12:36:11.661 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 << "[\r][\n]"
12:36:11.661 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [ACTIVE] [content length: 185; pos: 185; completed: true]
12:36:11.661 [I/O dispatcher 41] DEBUG org.apache.http.wire - http-outgoing-4 << "{"took":7,"errors":true,"items":[{"update":{"_index":"test_index","_type":"_doc","_id":"d","status":409,"error":{"type":"version_conflict_engine_exception","reason":"[d]: version conflict, required seqNo [12], primary term [1]. current document has seqNo [15] and primary term [1]","index_uuid":"m3mCLiSmQbugO4TXupHgrw","shard":"0","index":"test_index"}}}]}"
12:36:11.662 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 << HTTP/1.1 200 OK
12:36:11.662 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 << Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."
12:36:11.662 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 << content-type: application/json; charset=UTF-8
12:36:11.662 [I/O dispatcher 41] DEBUG org.apache.http.headers - http-outgoing-4 << content-length: 357
12:36:11.662 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [ACTIVE(357)] Response received
12:36:11.662 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 32] Response received HTTP/1.1 200 OK
12:36:11.662 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [ACTIVE(357)] Input ready
12:36:11.662 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 32] Consume content
12:36:11.662 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 32] Connection can be kept alive indefinitely
12:36:11.662 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 32] Response processed
12:36:11.662 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 32] releasing connection
12:36:11.662 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][r:r]: Remove attribute http.nio.exchange-handler
12:36:11.663 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-4][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:11.663 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection [id: http-outgoing-4][route: {}->http://127.0.0.1:9200] can be kept alive indefinitely
12:36:11.663 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:11.663 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-4][route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:11.663 [I/O dispatcher 41] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned [HTTP/1.1 200 OK]
12:36:11.663 [I/O dispatcher 41] WARN org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."]
12:36:11.664 [I/O dispatcher 41] ERROR org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase - Failed Elasticsearch item request: [test_index/m3mCLiSmQbugO4TXupHgrw][[test_index][0]] ElasticsearchException[Elasticsearch exception [type=version_conflict_engine_exception, reason=[d]: version conflict, required seqNo [12], primary term [1]. current document has seqNo [15] and primary term [1]]]
org.elasticsearch.ElasticsearchException: Elasticsearch exception [type=version_conflict_engine_exception, reason=[d]: version conflict, required seqNo [12], primary term [1]. current document has seqNo [15] and primary term [1]]
	at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:509)
	at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:420)
	at org.elasticsearch.action.bulk.BulkItemResponse.fromXContent(BulkItemResponse.java:135)
	at org.elasticsearch.action.bulk.BulkResponse.fromXContent(BulkResponse.java:198)
	at org.elasticsearch.client.RestHighLevelClient.parseEntity(RestHighLevelClient.java:1406)
	at org.elasticsearch.client.RestHighLevelClient.lambda$performRequestAsyncAndParseEntity$10(RestHighLevelClient.java:1284)
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:1334)
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:836)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:538)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:529)
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122)
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338)
	at org.apache.http.impl.nio.client.InternalRequestExecutor.inputReady(InternalRequestExecutor.java:83)
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591)
	at java.base/java.lang.Thread.run(Thread.java:834)
12:36:11.665 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [ACTIVE] [content length: 357; pos: 357; completed: true]
12:36:12.041 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:12.041 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:12.041 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1352) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:12.041 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:12.329 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][r:r]: 417 bytes read
12:36:12.329 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 << "HTTP/1.1 200 OK[\r][\n]"
12:36:12.329 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 << "Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."[\r][\n]"
12:36:12.329 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 << "content-type: application/json; charset=UTF-8[\r][\n]"
12:36:12.329 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 << "content-length: 221[\r][\n]"
12:36:12.329 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 << "[\r][\n]"
12:36:12.330 [I/O dispatcher 33] DEBUG org.apache.http.wire - http-outgoing-7 << "{"took":676,"errors":false,"items":[{"update":{"_index":"test_index","_type":"_doc","_id":"d","_version":3,"result":"updated","_shards":{"total":2,"successful":2,"failed":0},"_seq_no":15,"_primary_term":1,"status":200}}]}"
12:36:12.330 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 << HTTP/1.1 200 OK
12:36:12.330 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 << Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."
12:36:12.330 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 << content-type: application/json; charset=UTF-8
12:36:12.330 [I/O dispatcher 33] DEBUG org.apache.http.headers - http-outgoing-7 << content-length: 221
12:36:12.330 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [ACTIVE(221)] Response received
12:36:12.330 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 33] Response received HTTP/1.1 200 OK
12:36:12.330 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [ACTIVE(221)] Input ready
12:36:12.330 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 33] Consume content
12:36:12.331 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 33] Connection can be kept alive indefinitely
12:36:12.331 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 33] Response processed
12:36:12.331 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 33] releasing connection
12:36:12.331 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][r:r]: Remove attribute http.nio.exchange-handler
12:36:12.331 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-7][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:12.331 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection [id: http-outgoing-7][route: {}->http://127.0.0.1:9200] can be kept alive indefinitely
12:36:12.331 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:36:12.331 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-7][route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:36:12.331 [I/O dispatcher 33] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned [HTTP/1.1 200 OK]
12:36:12.332 [I/O dispatcher 33] WARN org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."]
12:36:12.333 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [ACTIVE] [content length: 221; pos: 221; completed: true]
12:36:12.515 [flink-akka.actor.default-dispatcher-119] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:36:12.515 [flink-akka.actor.default-dispatcher-122] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:36:12.515 [flink-akka.actor.default-dispatcher-119] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:36:12.515 [flink-akka.actor.default-dispatcher-122] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:36:12.516 [flink-akka.actor.default-dispatcher-123] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 621afbc6d2b245ff6afa7759e6d8da3a.
12:36:12.516 [flink-akka.actor.default-dispatcher-123] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:12.516 [flink-akka.actor.default-dispatcher-123] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received new slot report from TaskManager 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:12.516 [flink-akka.actor.default-dispatcher-123] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Received slot report from instance f2876166ab70148059ed9f2f9a72cef9.
12:36:12.544 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:12.544 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:12.544 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1353) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:12.545 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:13.047 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:13.047 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:13.047 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1354) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:13.047 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:13.550 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:13.550 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:13.550 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1355) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:13.550 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:13.915 [flink-akka.actor.default-dispatcher-123] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
12:36:13.916 [flink-akka.actor.default-dispatcher-123] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from 621afbc6d2b245ff6afa7759e6d8da3a.
12:36:13.917 [flink-akka.actor.default-dispatcher-123] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:14.053 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:14.053 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:14.053 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1356) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:14.053 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:14.556 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:14.556 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:14.556 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1357) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:14.556 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:14.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:14.792 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 33 for partition test-0
12:36:14.792 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:15.058 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:15.058 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:15.058 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1358) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:15.058 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:15.558 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:15.558 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:15.558 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1359) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:15.558 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:16.060 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:16.060 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:16.060 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1360) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:16.060 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:16.562 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:16.562 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:16.562 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1361) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:16.562 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:17.064 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:17.064 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:17.064 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1362) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:17.064 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:17.568 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:17.568 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:17.568 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1363) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:17.568 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:18.070 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:18.070 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:18.070 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1364) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:18.070 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:18.572 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:18.572 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:18.572 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1365) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:18.572 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:19.075 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:19.075 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:19.075 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1366) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:19.075 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:19.579 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:19.579 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:19.579 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1367) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:19.579 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:19.789 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:19.791 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 33 for partition test-0
12:36:19.791 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:20.081 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:20.081 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:20.081 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1368) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:20.081 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:20.584 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:20.584 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:20.584 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1369) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:20.584 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:21.087 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:21.087 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:21.087 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1370) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:21.087 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:21.589 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:21.590 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:21.590 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1371) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:21.590 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:22.091 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:22.092 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:22.092 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1372) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:22.092 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:22.520 [flink-akka.actor.default-dispatcher-119] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:36:22.520 [flink-akka.actor.default-dispatcher-124] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:36:22.521 [flink-akka.actor.default-dispatcher-124] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:36:22.521 [flink-akka.actor.default-dispatcher-119] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:36:22.522 [flink-akka.actor.default-dispatcher-125] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 621afbc6d2b245ff6afa7759e6d8da3a.
12:36:22.522 [flink-akka.actor.default-dispatcher-119] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:22.522 [flink-akka.actor.default-dispatcher-119] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received new slot report from TaskManager 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:22.523 [flink-akka.actor.default-dispatcher-119] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Received slot report from instance f2876166ab70148059ed9f2f9a72cef9.
12:36:22.595 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:22.595 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:22.595 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1373) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:22.595 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:23.099 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:23.099 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:23.099 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1374) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:23.099 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:23.602 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:23.602 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:23.602 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1375) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:23.602 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:23.892 [flink-akka.actor.default-dispatcher-119] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
12:36:23.892 [flink-akka.actor.default-dispatcher-124] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from 621afbc6d2b245ff6afa7759e6d8da3a.
12:36:23.893 [flink-akka.actor.default-dispatcher-124] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:24.105 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:24.105 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:24.105 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1376) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:24.105 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:24.607 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:24.608 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:24.608 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1377) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:24.608 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:24.789 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:24.793 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 33 for partition test-0
12:36:24.793 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:25.112 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:25.112 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:25.112 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1378) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:25.112 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:25.615 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:25.615 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:25.615 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1379) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:25.615 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:26.118 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:26.118 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:26.118 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1380) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:26.118 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:26.620 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:26.620 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:26.620 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1381) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:26.620 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:27.125 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:27.125 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:27.125 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1382) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:27.125 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:27.627 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:27.628 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:27.628 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1383) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:27.628 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:28.130 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:28.130 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:28.130 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1384) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:28.130 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:28.633 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:28.633 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:28.633 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1385) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:28.633 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:29.135 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:29.135 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:29.135 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1386) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:29.135 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:29.637 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:29.637 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:29.637 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1387) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:29.637 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:29.790 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:29.794 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 33 for partition test-0
12:36:29.794 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:30.139 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:30.139 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:30.139 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1388) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:30.139 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:30.641 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:30.641 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:30.641 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1389) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:30.641 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:31.144 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:31.144 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:31.144 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1390) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:31.144 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:31.647 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:31.647 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:31.647 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1391) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:31.647 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:32.150 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:32.150 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:32.150 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1392) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:32.150 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:32.521 [flink-akka.actor.default-dispatcher-125] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:36:32.522 [flink-akka.actor.default-dispatcher-126] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:36:32.523 [flink-akka.actor.default-dispatcher-126] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:32.523 [flink-akka.actor.default-dispatcher-126] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received new slot report from TaskManager 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:32.523 [flink-akka.actor.default-dispatcher-126] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Received slot report from instance f2876166ab70148059ed9f2f9a72cef9.
12:36:32.531 [flink-akka.actor.default-dispatcher-127] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:36:32.531 [flink-akka.actor.default-dispatcher-127] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:36:32.532 [flink-akka.actor.default-dispatcher-127] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 621afbc6d2b245ff6afa7759e6d8da3a.
12:36:32.652 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:32.652 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:32.652 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1393) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:32.652 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:33.155 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:33.155 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:33.155 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1394) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:33.155 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:33.657 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:33.657 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:33.657 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1395) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:33.658 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:33.910 [flink-akka.actor.default-dispatcher-127] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
12:36:33.910 [flink-akka.actor.default-dispatcher-125] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from 621afbc6d2b245ff6afa7759e6d8da3a.
12:36:33.911 [flink-akka.actor.default-dispatcher-125] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:34.160 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:34.160 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:34.160 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1396) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:34.160 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:34.663 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:34.663 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:34.663 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1397) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:34.663 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:34.791 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:34.795 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 33 for partition test-0
12:36:34.795 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:34.823 [flink-akka.actor.default-dispatcher-125] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Slot Pool Status:
	status: connected to akka://flink/user/resourcemanager_561724c3-ac3d-4ded-b450-27d306344362
	registered TaskManagers: [44d9f797-9615-4b31-b456-531e5238ff73]
	available slots: []
	allocated slots: [[AllocatedSlot AllocationID{75e09d17a2942a3065f51a6840a482ff} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 6, AllocatedSlot AllocationID{f13cb848b24e3e3e8e733b16004e062c} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 7, AllocatedSlot AllocationID{c0b004201bfbe3400cc808c96d8b8365} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 4, AllocatedSlot AllocationID{e758aac1ee5da11a6e9011f3605acd4f} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 1, AllocatedSlot AllocationID{9acab6076aac22871be5d350fba4ca31} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 0, AllocatedSlot AllocationID{05edcf935db937ae387c68dced2a94e4} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 3, AllocatedSlot AllocationID{ff0ef514b2463d2406ff304b42249356} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 2, AllocatedSlot AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 5]]
	pending requests: []
	sharing groups: {
	 -------- 576517cdb14ffcc6d1732962d417e42c --------
{
	groupId=576517cdb14ffcc6d1732962d417e42c
	unresolved={}
	resolved={44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1)=[MultiTaskSlot{requestId=SlotRequestId{2ea0871f39adc261baa4877ff3415202}, allocatedRequestId=SlotRequestId{67a6754dd39c86e1c29ff920a1ef76b2}, groupId=null, physicalSlot=AllocatedSlot AllocationID{05edcf935db937ae387c68dced2a94e4} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 3, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}, allocationId=AllocationID{05edcf935db937ae387c68dced2a94e4}), request=SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}, allocationId=AllocationID{05edcf935db937ae387c68dced2a94e4}), request=SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}, group=0a448493b4782967b150582570326227}]}, MultiTaskSlot{requestId=SlotRequestId{2a8e814a4731561378a993c0af76a933}, allocatedRequestId=SlotRequestId{6715ab7ec90dcfc0995fb5a87f03d354}, groupId=null, physicalSlot=AllocatedSlot AllocationID{9acab6076aac22871be5d350fba4ca31} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 0, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{887aa3ffc53e7b6ba987097678262d04}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{887aa3ffc53e7b6ba987097678262d04}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}, group=bc764cd8ddf7a0cff126f51c16239658}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{295c6c46a79d94283fa95042835e7518}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{295c6c46a79d94283fa95042835e7518}, group=0a448493b4782967b150582570326227}]}, MultiTaskSlot{requestId=SlotRequestId{736b8c6e155757c3cee0e39e16d9e44e}, allocatedRequestId=SlotRequestId{b1184ccf75ed3811528066775a34df21}, groupId=null, physicalSlot=AllocatedSlot AllocationID{f13cb848b24e3e3e8e733b16004e062c} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 7, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}, allocationId=AllocationID{f13cb848b24e3e3e8e733b16004e062c}), request=SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{ebd1ead0866ead21574aca31c67c747f}, allocationId=AllocationID{f13cb848b24e3e3e8e733b16004e062c}), request=SlotRequestId{ebd1ead0866ead21574aca31c67c747f}, group=0a448493b4782967b150582570326227}]}, MultiTaskSlot{requestId=SlotRequestId{aae221589bd5ca1f5951ce5b6cbe9397}, allocatedRequestId=SlotRequestId{23fb6480c6d050fb7421929760796332}, groupId=null, physicalSlot=AllocatedSlot AllocationID{c0b004201bfbe3400cc808c96d8b8365} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 4, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{6ae167cf815b656fd674e788559c727b}, allocationId=AllocationID{c0b004201bfbe3400cc808c96d8b8365}), request=SlotRequestId{6ae167cf815b656fd674e788559c727b}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}, allocationId=AllocationID{c0b004201bfbe3400cc808c96d8b8365}), request=SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}, group=0a448493b4782967b150582570326227}]}, MultiTaskSlot{requestId=SlotRequestId{a4e7689e9482fcb1b182017d220949d0}, allocatedRequestId=SlotRequestId{a63e244e13b46e0ec7cbe04c71b901dc}, groupId=null, physicalSlot=AllocatedSlot AllocationID{e758aac1ee5da11a6e9011f3605acd4f} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 1, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}, group=bc764cd8ddf7a0cff126f51c16239658}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{eb3f2c3195da229322e366bb5f054331}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{eb3f2c3195da229322e366bb5f054331}, group=0a448493b4782967b150582570326227}]}, MultiTaskSlot{requestId=SlotRequestId{7a254ff1e52d1c0d0d5e762f2782359f}, allocatedRequestId=SlotRequestId{44f4cbbbaf936a8acbeab99e3e6c5efb}, groupId=null, physicalSlot=AllocatedSlot AllocationID{75e09d17a2942a3065f51a6840a482ff} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 6, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}, allocationId=AllocationID{75e09d17a2942a3065f51a6840a482ff}), request=SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{8025cceab9f3884a0d5456814df81e66}, allocationId=AllocationID{75e09d17a2942a3065f51a6840a482ff}), request=SlotRequestId{8025cceab9f3884a0d5456814df81e66}, group=0a448493b4782967b150582570326227}]}, MultiTaskSlot{requestId=SlotRequestId{f85c81b8333fdf15e365d94f1a2aef3b}, allocatedRequestId=SlotRequestId{9225a682112ba3a8876a86624954f883}, groupId=null, physicalSlot=AllocatedSlot AllocationID{ff0ef514b2463d2406ff304b42249356} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 2, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{137314c001a9aa59f0514fb84a745561}, allocationId=AllocationID{ff0ef514b2463d2406ff304b42249356}), request=SlotRequestId{137314c001a9aa59f0514fb84a745561}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}, allocationId=AllocationID{ff0ef514b2463d2406ff304b42249356}), request=SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}, group=0a448493b4782967b150582570326227}]}, MultiTaskSlot{requestId=SlotRequestId{5033a864b671b2b3de3442756ff36370}, allocatedRequestId=SlotRequestId{3e7bd6b7d6e68acec9696656a198d3a6}, groupId=null, physicalSlot=AllocatedSlot AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 5, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}, allocationId=AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d}), request=SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{c5bc5ddca88560402317a675a5a740fe}, allocationId=AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d}), request=SlotRequestId{c5bc5ddca88560402317a675a5a740fe}, group=0a448493b4782967b150582570326227}]}]}
	all={SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}, allocationId=AllocationID{05edcf935db937ae387c68dced2a94e4}), request=SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}, group=51397532e2d9c7a21097a30d590b3114}, SlotRequestId{6ae167cf815b656fd674e788559c727b}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{6ae167cf815b656fd674e788559c727b}, allocationId=AllocationID{c0b004201bfbe3400cc808c96d8b8365}), request=SlotRequestId{6ae167cf815b656fd674e788559c727b}, group=51397532e2d9c7a21097a30d590b3114}, SlotRequestId{295c6c46a79d94283fa95042835e7518}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{295c6c46a79d94283fa95042835e7518}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{295c6c46a79d94283fa95042835e7518}, group=0a448493b4782967b150582570326227}, SlotRequestId{887aa3ffc53e7b6ba987097678262d04}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{887aa3ffc53e7b6ba987097678262d04}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{887aa3ffc53e7b6ba987097678262d04}, group=51397532e2d9c7a21097a30d590b3114}, SlotRequestId{2a8e814a4731561378a993c0af76a933}=MultiTaskSlot{requestId=SlotRequestId{2a8e814a4731561378a993c0af76a933}, allocatedRequestId=SlotRequestId{6715ab7ec90dcfc0995fb5a87f03d354}, groupId=null, physicalSlot=AllocatedSlot AllocationID{9acab6076aac22871be5d350fba4ca31} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 0, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{887aa3ffc53e7b6ba987097678262d04}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{887aa3ffc53e7b6ba987097678262d04}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}, group=bc764cd8ddf7a0cff126f51c16239658}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{295c6c46a79d94283fa95042835e7518}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{295c6c46a79d94283fa95042835e7518}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}, allocationId=AllocationID{c0b004201bfbe3400cc808c96d8b8365}), request=SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}, group=0a448493b4782967b150582570326227}, SlotRequestId{aae221589bd5ca1f5951ce5b6cbe9397}=MultiTaskSlot{requestId=SlotRequestId{aae221589bd5ca1f5951ce5b6cbe9397}, allocatedRequestId=SlotRequestId{23fb6480c6d050fb7421929760796332}, groupId=null, physicalSlot=AllocatedSlot AllocationID{c0b004201bfbe3400cc808c96d8b8365} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 4, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{6ae167cf815b656fd674e788559c727b}, allocationId=AllocationID{c0b004201bfbe3400cc808c96d8b8365}), request=SlotRequestId{6ae167cf815b656fd674e788559c727b}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}, allocationId=AllocationID{c0b004201bfbe3400cc808c96d8b8365}), request=SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{5033a864b671b2b3de3442756ff36370}=MultiTaskSlot{requestId=SlotRequestId{5033a864b671b2b3de3442756ff36370}, allocatedRequestId=SlotRequestId{3e7bd6b7d6e68acec9696656a198d3a6}, groupId=null, physicalSlot=AllocatedSlot AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 5, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}, allocationId=AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d}), request=SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{c5bc5ddca88560402317a675a5a740fe}, allocationId=AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d}), request=SlotRequestId{c5bc5ddca88560402317a675a5a740fe}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}, allocationId=AllocationID{9acab6076aac22871be5d350fba4ca31}), request=SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}, group=bc764cd8ddf7a0cff126f51c16239658}, SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}, group=51397532e2d9c7a21097a30d590b3114}, SlotRequestId{7a254ff1e52d1c0d0d5e762f2782359f}=MultiTaskSlot{requestId=SlotRequestId{7a254ff1e52d1c0d0d5e762f2782359f}, allocatedRequestId=SlotRequestId{44f4cbbbaf936a8acbeab99e3e6c5efb}, groupId=null, physicalSlot=AllocatedSlot AllocationID{75e09d17a2942a3065f51a6840a482ff} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 6, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}, allocationId=AllocationID{75e09d17a2942a3065f51a6840a482ff}), request=SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{8025cceab9f3884a0d5456814df81e66}, allocationId=AllocationID{75e09d17a2942a3065f51a6840a482ff}), request=SlotRequestId{8025cceab9f3884a0d5456814df81e66}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}, allocationId=AllocationID{75e09d17a2942a3065f51a6840a482ff}), request=SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}, group=51397532e2d9c7a21097a30d590b3114}, SlotRequestId{c5bc5ddca88560402317a675a5a740fe}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{c5bc5ddca88560402317a675a5a740fe}, allocationId=AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d}), request=SlotRequestId{c5bc5ddca88560402317a675a5a740fe}, group=0a448493b4782967b150582570326227}, SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}, allocationId=AllocationID{05edcf935db937ae387c68dced2a94e4}), request=SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}, group=0a448493b4782967b150582570326227}, SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}, group=bc764cd8ddf7a0cff126f51c16239658}, SlotRequestId{2ea0871f39adc261baa4877ff3415202}=MultiTaskSlot{requestId=SlotRequestId{2ea0871f39adc261baa4877ff3415202}, allocatedRequestId=SlotRequestId{67a6754dd39c86e1c29ff920a1ef76b2}, groupId=null, physicalSlot=AllocatedSlot AllocationID{05edcf935db937ae387c68dced2a94e4} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 3, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}, allocationId=AllocationID{05edcf935db937ae387c68dced2a94e4}), request=SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}, allocationId=AllocationID{05edcf935db937ae387c68dced2a94e4}), request=SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{eb3f2c3195da229322e366bb5f054331}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{eb3f2c3195da229322e366bb5f054331}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{eb3f2c3195da229322e366bb5f054331}, group=0a448493b4782967b150582570326227}, SlotRequestId{a4e7689e9482fcb1b182017d220949d0}=MultiTaskSlot{requestId=SlotRequestId{a4e7689e9482fcb1b182017d220949d0}, allocatedRequestId=SlotRequestId{a63e244e13b46e0ec7cbe04c71b901dc}, groupId=null, physicalSlot=AllocatedSlot AllocationID{e758aac1ee5da11a6e9011f3605acd4f} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 1, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}, group=bc764cd8ddf7a0cff126f51c16239658}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{eb3f2c3195da229322e366bb5f054331}, allocationId=AllocationID{e758aac1ee5da11a6e9011f3605acd4f}), request=SlotRequestId{eb3f2c3195da229322e366bb5f054331}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}, allocationId=AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d}), request=SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}, group=51397532e2d9c7a21097a30d590b3114}, SlotRequestId{f85c81b8333fdf15e365d94f1a2aef3b}=MultiTaskSlot{requestId=SlotRequestId{f85c81b8333fdf15e365d94f1a2aef3b}, allocatedRequestId=SlotRequestId{9225a682112ba3a8876a86624954f883}, groupId=null, physicalSlot=AllocatedSlot AllocationID{ff0ef514b2463d2406ff304b42249356} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 2, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{137314c001a9aa59f0514fb84a745561}, allocationId=AllocationID{ff0ef514b2463d2406ff304b42249356}), request=SlotRequestId{137314c001a9aa59f0514fb84a745561}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}, allocationId=AllocationID{ff0ef514b2463d2406ff304b42249356}), request=SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}, allocationId=AllocationID{f13cb848b24e3e3e8e733b16004e062c}), request=SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}, group=51397532e2d9c7a21097a30d590b3114}, SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}, allocationId=AllocationID{ff0ef514b2463d2406ff304b42249356}), request=SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}, group=0a448493b4782967b150582570326227}, SlotRequestId{ebd1ead0866ead21574aca31c67c747f}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{ebd1ead0866ead21574aca31c67c747f}, allocationId=AllocationID{f13cb848b24e3e3e8e733b16004e062c}), request=SlotRequestId{ebd1ead0866ead21574aca31c67c747f}, group=0a448493b4782967b150582570326227}, SlotRequestId{736b8c6e155757c3cee0e39e16d9e44e}=MultiTaskSlot{requestId=SlotRequestId{736b8c6e155757c3cee0e39e16d9e44e}, allocatedRequestId=SlotRequestId{b1184ccf75ed3811528066775a34df21}, groupId=null, physicalSlot=AllocatedSlot AllocationID{f13cb848b24e3e3e8e733b16004e062c} @ 44d9f797-9615-4b31-b456-531e5238ff73 @ kubernetes.docker.internal (dataPort=-1) - 7, children=[SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}, allocationId=AllocationID{f13cb848b24e3e3e8e733b16004e062c}), request=SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}, group=51397532e2d9c7a21097a30d590b3114}, SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{ebd1ead0866ead21574aca31c67c747f}, allocationId=AllocationID{f13cb848b24e3e3e8e733b16004e062c}), request=SlotRequestId{ebd1ead0866ead21574aca31c67c747f}, group=0a448493b4782967b150582570326227}]}, SlotRequestId{8025cceab9f3884a0d5456814df81e66}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{8025cceab9f3884a0d5456814df81e66}, allocationId=AllocationID{75e09d17a2942a3065f51a6840a482ff}), request=SlotRequestId{8025cceab9f3884a0d5456814df81e66}, group=0a448493b4782967b150582570326227}, SlotRequestId{137314c001a9aa59f0514fb84a745561}=SingleTaskSlot{logicalSlot=(requestId=SlotRequestId{137314c001a9aa59f0514fb84a745561}, allocationId=AllocationID{ff0ef514b2463d2406ff304b42249356}), request=SlotRequestId{137314c001a9aa59f0514fb84a745561}, group=51397532e2d9c7a21097a30d590b3114}}
}	}

12:36:35.166 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:35.166 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:35.166 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1398) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:35.166 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:35.668 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:35.668 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:35.668 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1399) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:35.668 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:36.170 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:36.170 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:36.170 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1400) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:36.170 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:36.672 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:36.672 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:36.672 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1401) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:36.672 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:37.174 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:37.175 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:37.175 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1402) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:37.175 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:37.677 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:37.677 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:37.677 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1403) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:37.677 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:38.179 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:38.179 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:38.179 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1404) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:38.179 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:38.681 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:38.681 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:38.681 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1405) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:38.681 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:39.185 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:39.185 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:39.185 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1406) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:39.186 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:39.688 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:39.688 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:39.688 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1407) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:39.688 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:39.792 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:39.795 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 33 for partition test-0
12:36:39.795 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:40.192 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:40.192 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:40.192 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1408) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:40.192 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:40.694 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:40.695 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:40.695 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1409) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:40.695 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:41.199 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:41.199 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:41.199 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1410) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:41.199 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:41.702 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:41.702 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:41.702 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1411) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:41.702 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:42.204 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:42.204 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:42.204 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1412) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:42.204 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:42.524 [flink-akka.actor.default-dispatcher-126] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:36:42.524 [flink-akka.actor.default-dispatcher-127] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:36:42.524 [flink-akka.actor.default-dispatcher-127] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:36:42.524 [flink-akka.actor.default-dispatcher-126] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:36:42.524 [flink-akka.actor.default-dispatcher-127] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 621afbc6d2b245ff6afa7759e6d8da3a.
12:36:42.525 [flink-akka.actor.default-dispatcher-129] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:42.525 [flink-akka.actor.default-dispatcher-129] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received new slot report from TaskManager 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:42.525 [flink-akka.actor.default-dispatcher-129] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Received slot report from instance f2876166ab70148059ed9f2f9a72cef9.
12:36:42.708 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:42.708 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:42.708 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1413) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:42.708 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:43.210 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:43.210 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:43.210 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1414) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:43.210 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:43.713 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:43.713 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:43.713 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1415) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:43.713 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:43.912 [flink-akka.actor.default-dispatcher-129] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
12:36:43.912 [flink-akka.actor.default-dispatcher-129] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from 621afbc6d2b245ff6afa7759e6d8da3a.
12:36:43.913 [flink-akka.actor.default-dispatcher-126] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:44.215 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:44.215 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:44.215 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1416) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:44.215 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:44.717 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:44.717 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:44.717 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1417) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:44.717 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:44.793 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:44.797 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 33 for partition test-0
12:36:44.797 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:45.219 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:45.219 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:45.219 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1418) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:45.219 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:45.722 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:45.722 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:45.722 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1419) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:45.722 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:46.226 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:46.226 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:46.226 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1420) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:46.226 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:46.730 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:46.730 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:46.730 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1421) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:46.730 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:47.235 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:47.235 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:47.235 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1422) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:47.235 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:47.737 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:47.737 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:47.737 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1423) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:47.737 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:48.239 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:48.239 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:48.239 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1424) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:48.239 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:48.743 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:48.743 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:48.743 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1425) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:48.743 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:49.246 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:49.247 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:49.247 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1426) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:49.247 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:49.749 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:49.749 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:49.749 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1427) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:49.749 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:49.793 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:49.794 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 33 for partition test-0
12:36:49.794 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:50.250 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:50.250 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:50.251 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1428) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:50.251 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:50.752 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:50.752 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:50.752 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1429) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:50.752 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:51.254 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:51.254 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:51.254 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1430) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:51.254 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:51.756 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:51.756 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:51.756 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1431) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:51.756 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:52.259 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:52.259 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:52.259 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1432) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:52.260 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:52.519 [flink-akka.actor.default-dispatcher-128] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:36:52.520 [flink-akka.actor.default-dispatcher-127] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:36:52.520 [flink-akka.actor.default-dispatcher-127] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:36:52.520 [flink-akka.actor.default-dispatcher-128] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:36:52.520 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 621afbc6d2b245ff6afa7759e6d8da3a.
12:36:52.521 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:52.521 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received new slot report from TaskManager 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:52.521 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Received slot report from instance f2876166ab70148059ed9f2f9a72cef9.
12:36:52.761 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:52.761 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:52.761 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1433) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:52.761 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:53.263 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:53.263 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:53.263 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1434) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:53.263 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:53.765 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:53.766 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:53.766 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1435) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:53.766 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:53.910 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
12:36:53.910 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from 621afbc6d2b245ff6afa7759e6d8da3a.
12:36:53.912 [flink-akka.actor.default-dispatcher-127] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:36:54.266 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:54.266 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:54.266 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1436) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:54.266 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:54.768 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:54.769 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:54.769 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1437) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:54.769 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:54.794 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:54.798 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 33 for partition test-0
12:36:54.798 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:55.269 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:55.269 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:55.269 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1438) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:55.269 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:55.771 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:55.771 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:55.771 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1439) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:55.771 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:56.272 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:56.273 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:56.273 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1440) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:56.273 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:56.774 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:56.774 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:56.774 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1441) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:56.774 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:57.277 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:57.277 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:57.277 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1442) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:57.277 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:57.780 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:57.780 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:57.780 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1443) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:57.780 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:58.282 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:58.282 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:58.282 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1444) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:58.282 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:58.785 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:58.785 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:58.785 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1445) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:58.785 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:59.287 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:59.287 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:59.287 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1446) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:59.287 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:59.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:36:59.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:59.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1447) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:36:59.788 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:36:59.794 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:36:59.796 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 33 for partition test-0
12:36:59.796 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:37:00.292 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:37:00.292 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:00.292 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1448) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:00.292 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:00.796 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:37:00.796 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:00.796 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1449) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:00.796 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:01.298 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:37:01.298 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:01.298 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1450) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:01.298 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:01.800 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:37:01.800 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:01.800 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1451) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:01.800 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:02.303 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:37:02.303 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:02.303 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1452) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:02.303 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:02.525 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:37:02.525 [flink-akka.actor.default-dispatcher-128] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:37:02.525 [flink-akka.actor.default-dispatcher-128] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:37:02.525 [flink-akka.actor.default-dispatcher-128] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received new slot report from TaskManager 44d9f797-9615-4b31-b456-531e5238ff73.
12:37:02.525 [flink-akka.actor.default-dispatcher-128] DEBUG org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Received slot report from instance f2876166ab70148059ed9f2f9a72cef9.
12:37:02.529 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Trigger heartbeat request.
12:37:02.529 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat request from cf9fe1aae908f5a6b873af96570f8b3b.
12:37:02.529 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Received heartbeat from 621afbc6d2b245ff6afa7759e6d8da3a.
12:37:02.806 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:37:02.806 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:02.806 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1453) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:02.806 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:03.308 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:37:03.308 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:03.308 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1454) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:03.308 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:03.811 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:37:03.811 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:03.811 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1455) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:03.811 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:03.911 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Trigger heartbeat request.
12:37:03.911 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.taskexecutor.TaskExecutor - Received heartbeat request from 621afbc6d2b245ff6afa7759e6d8da3a.
12:37:03.911 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Received heartbeat from 44d9f797-9615-4b31-b456-531e5238ff73.
12:37:04.312 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:37:04.312 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:04.312 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1456) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:04.312 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:04.795 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:37:04.799 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 33 for partition test-0
12:37:04.799 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Completed asynchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=33, metadata=''}}
12:37:04.814 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:37:04.814 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:04.814 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1457) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:04.814 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:05.318 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:37:05.318 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:05.318 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1458) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:05.318 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:05.820 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:37:05.820 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:05.820 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1459) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:05.820 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:06.323 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:37:06.323 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:06.323 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1460) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:06.323 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:06.826 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 0 response partition(s), 1 implied partition(s)
12:37:06.826 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 33 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:06.826 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1461) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:06.826 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(test-0)) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:06.986 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Node 0 sent an incremental fetch response for session 360945527 with 1 response partition(s)
12:37:06.986 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Fetch READ_UNCOMMITTED at offset 33 for partition test-0 returned fetch data (error=NONE, highWaterMark=37, lastStableOffset = 37, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=96)
12:37:06.988 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Added READ_UNCOMMITTED fetch request for partition test-0 at offset 37 to node DESKTOP-BI943HU:9092 (id: 0 rack: null)
12:37:06.988 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-4, groupId=flink-test] Built incremental fetch (sessionId=360945527, epoch=1462) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
12:37:06.988 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-4, groupId=flink-test] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(test-0), toForget=(), implied=()) to broker DESKTOP-BI943HU:9092 (id: 0 rack: null)
kafka:e
5> e
3> e
6> e
4> e
kafka:e
kafka:e
kafka:e
5> (e,5)
4> (e,5)
6> (e,5)
3> (e,5)
12:37:07.003 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 35] start execution
12:37:07.003 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 37] start execution
12:37:07.003 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 36] start execution
12:37:07.004 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:37:07.005 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:37:07.005 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.client.protocol.RequestAddCookies - CookieSpec selected: default
12:37:07.005 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:37:07.005 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:37:07.005 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:37:07.005 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 35] Request connection for {}->http://127.0.0.1:9200
12:37:07.005 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:37:07.005 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - Re-using cached 'basic' auth scheme for http://127.0.0.1:9200
12:37:07.006 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 37] Request connection for {}->http://127.0.0.1:9200
12:37:07.006 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.client.protocol.RequestAuthCache - No credentials for preemptive authentication
12:37:07.006 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:37:07.006 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 36] Request connection for {}->http://127.0.0.1:9200
12:37:07.006 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:37:07.006 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection request: [route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:37:07.006 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:37:07.006 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:37:07.006 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:37:07.006 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-0][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:37:07.006 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-2][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:37:07.007 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection leased: [id: http-outgoing-6][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:37:07.007 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 37] Connection allocated: CPoolProxy{http-outgoing-2 [ACTIVE]}
12:37:07.007 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 35] Connection allocated: CPoolProxy{http-outgoing-0 [ACTIVE]}
12:37:07.007 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:37:07.007 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 36] Connection allocated: CPoolProxy{http-outgoing-6 [ACTIVE]}
12:37:07.007 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:37:07.007 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][r:r]: Set attribute http.nio.exchange-handler
12:37:07.007 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][rw:r]: Event set [w]
12:37:07.007 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][rw:r]: Event set [w]
12:37:07.007 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [ACTIVE] Request ready
12:37:07.008 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-0 [ACTIVE] Request ready
12:37:07.008 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [ACTIVE] Request ready
12:37:07.008 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:37:07.008 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 36] Attempt 1 to execute request
12:37:07.008 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 37] Attempt 1 to execute request
12:37:07.008 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 36] Target auth state: UNCHALLENGED
12:37:07.008 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 37] Target auth state: UNCHALLENGED
12:37:07.008 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 35] Attempt 1 to execute request
12:37:07.008 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 37] Proxy auth state: UNCHALLENGED
12:37:07.008 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 36] Proxy auth state: UNCHALLENGED
12:37:07.008 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 35] Target auth state: UNCHALLENGED
12:37:07.008 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:37:07.008 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:37:07.008 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 >> POST /_bulk?timeout=1m HTTP/1.1
12:37:07.008 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 35] Proxy auth state: UNCHALLENGED
12:37:07.008 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 >> Content-Length: 102
12:37:07.008 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 >> Content-Type: application/json
12:37:07.008 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 >> Host: 127.0.0.1:9200
12:37:07.008 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 >> POST /_bulk?timeout=1m HTTP/1.1
12:37:07.009 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 >> Content-Length: 102
12:37:07.009 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 >> Content-Type: application/json
12:37:07.009 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 >> Host: 127.0.0.1:9200
12:37:07.009 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 >> Connection: Keep-Alive
12:37:07.009 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 >> Connection: Keep-Alive
12:37:07.009 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][rw:w]: Set timeout 30000
12:37:07.009 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:37:07.009 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:37:07.009 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 >> POST /_bulk?timeout=1m HTTP/1.1
12:37:07.009 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 >> Content-Length: 102
12:37:07.009 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 >> Content-Type: application/json
12:37:07.009 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 >> Host: 127.0.0.1:9200
12:37:07.009 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 >> Connection: Keep-Alive
12:37:07.009 [I/O dispatcher 57] DEBUG org.apache.http.headers - http-outgoing-0 >> User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)
12:37:07.010 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:37:07.010 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:37:07.010 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [ACTIVE] Output ready
12:37:07.010 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [ACTIVE] Output ready
12:37:07.010 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 36] produce content
12:37:07.010 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 37] produce content
12:37:07.010 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][rw:w]: Event set [w]
12:37:07.010 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-0 [ACTIVE] Output ready
12:37:07.010 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 36] Request completed
12:37:07.010 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 35] produce content
12:37:07.010 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [ACTIVE] [content length: 102; pos: 102; completed: true]
12:37:07.010 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 37] Request completed
12:37:07.010 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 35] Request completed
12:37:07.010 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [ACTIVE] [content length: 102; pos: 102; completed: true]
12:37:07.011 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-0 [ACTIVE] [content length: 102; pos: 102; completed: true]
12:37:07.011 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][rw:w]: 292 bytes written
12:37:07.011 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][rw:w]: 292 bytes written
12:37:07.011 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][rw:w]: 292 bytes written
12:37:07.011 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:37:07.011 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:37:07.011 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "POST /_bulk?timeout=1m HTTP/1.1[\r][\n]"
12:37:07.011 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "Content-Length: 102[\r][\n]"
12:37:07.011 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "Content-Length: 102[\r][\n]"
12:37:07.011 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "Content-Length: 102[\r][\n]"
12:37:07.011 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "Content-Type: application/json[\r][\n]"
12:37:07.012 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "Content-Type: application/json[\r][\n]"
12:37:07.012 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "Host: 127.0.0.1:9200[\r][\n]"
12:37:07.012 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "Content-Type: application/json[\r][\n]"
12:37:07.012 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "Host: 127.0.0.1:9200[\r][\n]"
12:37:07.012 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "Connection: Keep-Alive[\r][\n]"
12:37:07.012 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "Connection: Keep-Alive[\r][\n]"
12:37:07.012 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "Host: 127.0.0.1:9200[\r][\n]"
12:37:07.012 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "Connection: Keep-Alive[\r][\n]"
12:37:07.012 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:37:07.012 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "[\r][\n]"
12:37:07.012 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:37:07.012 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "[\r][\n]"
12:37:07.012 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "User-Agent: Apache-HttpAsyncClient/4.1.4 (Java/11.0.2)[\r][\n]"
12:37:07.012 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "[\r][\n]"
12:37:07.012 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"e"}}[\n]"
12:37:07.012 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"e"}}[\n]"
12:37:07.013 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "{"update":{"_index":"test_index","_type":"_doc","_id":"e"}}[\n]"
12:37:07.013 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 >> "{"doc_as_upsert":true,"doc":{"status":5}}[\n]"
12:37:07.013 [I/O dispatcher 57] DEBUG org.apache.http.wire - http-outgoing-0 >> "{"doc_as_upsert":true,"doc":{"status":5}}[\n]"
12:37:07.013 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 >> "{"doc_as_upsert":true,"doc":{"status":5}}[\n]"
12:37:07.013 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [ACTIVE] Request ready
12:37:07.013 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-0 [ACTIVE] Request ready
12:37:07.013 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [ACTIVE] Request ready
12:37:07.013 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:37:07.013 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:37:07.013 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][r:w]: Event cleared [w]
12:37:07.019 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager is shutting down
12:37:07.020 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-3 127.0.0.1:53913<->127.0.0.1:9200[ACTIVE][r:r]: Close
12:37:07.023 [I/O dispatcher 1] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-3 [CLOSED]: Disconnected
12:37:07.030 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager shut down
12:37:07.030 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] ERROR org.apache.flink.streaming.runtime.tasks.StreamTask - Error during disposal of stream operator.
java.lang.RuntimeException: An error occurred in ElasticsearchSink.
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.checkErrorAndRethrow(ElasticsearchSinkBase.java:379)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.close(ElasticsearchSinkBase.java:341)
	at org.apache.flink.api.common.functions.util.FunctionUtils.closeFunction(FunctionUtils.java:43)
	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.dispose(AbstractUdfStreamOperator.java:117)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.disposeAllOperators(StreamTask.java:477)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:378)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.elasticsearch.ElasticsearchException: Elasticsearch exception [type=version_conflict_engine_exception, reason=[e]: version conflict, required seqNo [8], primary term [1]. current document has seqNo [14] and primary term [1]]
	at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:509)
	at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:420)
	at org.elasticsearch.action.bulk.BulkItemResponse.fromXContent(BulkItemResponse.java:135)
	at org.elasticsearch.action.bulk.BulkResponse.fromXContent(BulkResponse.java:198)
	at org.elasticsearch.client.RestHighLevelClient.parseEntity(RestHighLevelClient.java:1406)
	at org.elasticsearch.client.RestHighLevelClient.lambda$performRequestAsyncAndParseEntity$10(RestHighLevelClient.java:1284)
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:1334)
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:836)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:538)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:529)
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122)
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338)
	at org.apache.http.impl.nio.client.InternalRequestExecutor.inputReady(InternalRequestExecutor.java:83)
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591)
	... 1 common frames omitted
12:37:07.032 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][r:r]: 554 bytes read
12:37:07.032 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 << "HTTP/1.1 200 OK[\r][\n]"
12:37:07.032 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 << "Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."[\r][\n]"
12:37:07.032 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 << "content-type: application/json; charset=UTF-8[\r][\n]"
12:37:07.032 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 << "content-length: 358[\r][\n]"
12:37:07.032 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 << "[\r][\n]"
12:37:07.032 [I/O dispatcher 9] DEBUG org.apache.http.wire - http-outgoing-2 << "{"took":19,"errors":true,"items":[{"update":{"_index":"test_index","_type":"_doc","_id":"e","status":409,"error":{"type":"version_conflict_engine_exception","reason":"[e]: version conflict, required seqNo [14], primary term [1]. current document has seqNo [16] and primary term [1]","index_uuid":"m3mCLiSmQbugO4TXupHgrw","shard":"0","index":"test_index"}}}]}"
12:37:07.033 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 << HTTP/1.1 200 OK
12:37:07.033 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 << Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."
12:37:07.033 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 << content-type: application/json; charset=UTF-8
12:37:07.033 [I/O dispatcher 9] DEBUG org.apache.http.headers - http-outgoing-2 << content-length: 358
12:37:07.033 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [ACTIVE(358)] Response received
12:37:07.033 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 37] Response received HTTP/1.1 200 OK
12:37:07.033 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [ACTIVE(358)] Input ready
12:37:07.033 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 37] Consume content
12:37:07.033 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8) (4835c6c99eeb1c88e9349fda2b9ee046) switched from RUNNING to FAILED.
java.lang.RuntimeException: An error occurred in ElasticsearchSink.
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.checkErrorAndRethrow(ElasticsearchSinkBase.java:379)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.invoke(ElasticsearchSinkBase.java:304)
	at org.apache.flink.streaming.api.functions.sink.SinkFunction.invoke(SinkFunction.java:52)
	at org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:56)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:649)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:602)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamFilter.processElement(StreamFilter.java:40)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:202)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:105)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:300)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.elasticsearch.ElasticsearchException: Elasticsearch exception [type=version_conflict_engine_exception, reason=[e]: version conflict, required seqNo [8], primary term [1]. current document has seqNo [14] and primary term [1]]
	at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:509)
	at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:420)
	at org.elasticsearch.action.bulk.BulkItemResponse.fromXContent(BulkItemResponse.java:135)
	at org.elasticsearch.action.bulk.BulkResponse.fromXContent(BulkResponse.java:198)
	at org.elasticsearch.client.RestHighLevelClient.parseEntity(RestHighLevelClient.java:1406)
	at org.elasticsearch.client.RestHighLevelClient.lambda$performRequestAsyncAndParseEntity$10(RestHighLevelClient.java:1284)
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:1334)
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:836)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:538)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:529)
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122)
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338)
	at org.apache.http.impl.nio.client.InternalRequestExecutor.inputReady(InternalRequestExecutor.java:83)
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591)
	... 1 common frames omitted
12:37:07.034 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 37] Connection can be kept alive indefinitely
12:37:07.034 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 37] Response processed
12:37:07.034 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 37] releasing connection
12:37:07.034 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][r:r]: Remove attribute http.nio.exchange-handler
12:37:07.034 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-2][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:37:07.034 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection [id: http-outgoing-2][route: {}->http://127.0.0.1:9200] can be kept alive indefinitely
12:37:07.034 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:37:07.034 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-2][route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:37:07.034 [I/O dispatcher 9] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned [HTTP/1.1 200 OK]
12:37:07.035 [I/O dispatcher 9] WARN org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."]
12:37:07.036 [I/O dispatcher 9] ERROR org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase - Failed Elasticsearch item request: [test_index/m3mCLiSmQbugO4TXupHgrw][[test_index][0]] ElasticsearchException[Elasticsearch exception [type=version_conflict_engine_exception, reason=[e]: version conflict, required seqNo [14], primary term [1]. current document has seqNo [16] and primary term [1]]]
org.elasticsearch.ElasticsearchException: Elasticsearch exception [type=version_conflict_engine_exception, reason=[e]: version conflict, required seqNo [14], primary term [1]. current document has seqNo [16] and primary term [1]]
	at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:509)
	at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:420)
	at org.elasticsearch.action.bulk.BulkItemResponse.fromXContent(BulkItemResponse.java:135)
	at org.elasticsearch.action.bulk.BulkResponse.fromXContent(BulkResponse.java:198)
	at org.elasticsearch.client.RestHighLevelClient.parseEntity(RestHighLevelClient.java:1406)
	at org.elasticsearch.client.RestHighLevelClient.lambda$performRequestAsyncAndParseEntity$10(RestHighLevelClient.java:1284)
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:1334)
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:836)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:538)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:529)
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122)
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338)
	at org.apache.http.impl.nio.client.InternalRequestExecutor.inputReady(InternalRequestExecutor.java:83)
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591)
	at java.base/java.lang.Thread.run(Thread.java:834)
12:37:07.036 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [ACTIVE] [content length: 358; pos: 358; completed: true]
12:37:07.055 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8) (4835c6c99eeb1c88e9349fda2b9ee046).
12:37:07.055 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8) from network environment (state: FAILED).
12:37:07.069 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by 4835c6c99eeb1c88e9349fda2b9ee046.
12:37:07.070 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8) (4835c6c99eeb1c88e9349fda2b9ee046): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@7d222b3b.
12:37:07.070 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition - ResultPartition 8e679901eefd2a043115970b09fcd8ec@5c92b8f60f982ce6ed1119e9dd227703 [PIPELINED_BOUNDED, 8 subpartitions, 7 pending references]: Received release notification for subpartition 4 (reference count now at: 7).
12:37:07.070 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition - ResultPartition c478dac72c53a389dd994de00ce05b8b@bcef77c1d6a9777e909a0ae0592ad637 [PIPELINED_BOUNDED, 8 subpartitions, 7 pending references]: Received release notification for subpartition 4 (reference count now at: 7).
12:37:07.070 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8) (4835c6c99eeb1c88e9349fda2b9ee046) [FAILED]
12:37:07.070 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state FAILED to JobManager for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) 4835c6c99eeb1c88e9349fda2b9ee046.
12:37:07.073 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (5/8) (4835c6c99eeb1c88e9349fda2b9ee046) switched from RUNNING to FAILED.
java.lang.RuntimeException: An error occurred in ElasticsearchSink.
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.checkErrorAndRethrow(ElasticsearchSinkBase.java:379)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.invoke(ElasticsearchSinkBase.java:304)
	at org.apache.flink.streaming.api.functions.sink.SinkFunction.invoke(SinkFunction.java:52)
	at org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:56)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:649)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:602)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamFilter.processElement(StreamFilter.java:40)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:202)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:105)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:300)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.elasticsearch.ElasticsearchException: Elasticsearch exception [type=version_conflict_engine_exception, reason=[e]: version conflict, required seqNo [8], primary term [1]. current document has seqNo [14] and primary term [1]]
	at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:509)
	at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:420)
	at org.elasticsearch.action.bulk.BulkItemResponse.fromXContent(BulkItemResponse.java:135)
	at org.elasticsearch.action.bulk.BulkResponse.fromXContent(BulkResponse.java:198)
	at org.elasticsearch.client.RestHighLevelClient.parseEntity(RestHighLevelClient.java:1406)
	at org.elasticsearch.client.RestHighLevelClient.lambda$performRequestAsyncAndParseEntity$10(RestHighLevelClient.java:1284)
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:1334)
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:836)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:538)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:529)
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122)
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338)
	at org.apache.http.impl.nio.client.InternalRequestExecutor.inputReady(InternalRequestExecutor.java:83)
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591)
	... 1 common frames omitted
12:37:07.074 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job this-test (0112c0387c891788cf37a4fab90f26d5) switched from state RUNNING to FAILING.
java.lang.RuntimeException: An error occurred in ElasticsearchSink.
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.checkErrorAndRethrow(ElasticsearchSinkBase.java:379)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.invoke(ElasticsearchSinkBase.java:304)
	at org.apache.flink.streaming.api.functions.sink.SinkFunction.invoke(SinkFunction.java:52)
	at org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:56)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:649)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:602)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamFilter.processElement(StreamFilter.java:40)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:202)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:105)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:300)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.elasticsearch.ElasticsearchException: Elasticsearch exception [type=version_conflict_engine_exception, reason=[e]: version conflict, required seqNo [8], primary term [1]. current document has seqNo [14] and primary term [1]]
	at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:509)
	at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:420)
	at org.elasticsearch.action.bulk.BulkItemResponse.fromXContent(BulkItemResponse.java:135)
	at org.elasticsearch.action.bulk.BulkResponse.fromXContent(BulkResponse.java:198)
	at org.elasticsearch.client.RestHighLevelClient.parseEntity(RestHighLevelClient.java:1406)
	at org.elasticsearch.client.RestHighLevelClient.lambda$performRequestAsyncAndParseEntity$10(RestHighLevelClient.java:1284)
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:1334)
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:836)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:538)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:529)
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122)
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338)
	at org.apache.http.impl.nio.client.InternalRequestExecutor.inputReady(InternalRequestExecutor.java:83)
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591)
	... 1 common frames omitted
12:37:07.079 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637) switched from RUNNING to CANCELING.
12:37:07.080 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637).
12:37:07.080 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637) switched from RUNNING to CANCELING.
12:37:07.082 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703) switched from RUNNING to CANCELING.
12:37:07.082 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637).
12:37:07.083 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/8) (9a3353529d19b6e60f77fdaf331ae33d) switched from RUNNING to CANCELING.
12:37:07.083 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (2/8) (9c35784f2b94203761e88741e589c808) switched from RUNNING to CANCELING.
12:37:07.083 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (3/8) (0f3a0ec033281cc7e0a745c8f6c3c01f) switched from RUNNING to CANCELING.
12:37:07.083 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (4/8) (afd4b5e133e3f4b330525405bc11061f) switched from RUNNING to CANCELING.
12:37:07.084 [Canceler for Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637).] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-4, groupId=flink-test] Received user wakeup
12:37:07.084 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (5/8) (671f7f548d794ffcad3ccbfc64b30959) switched from RUNNING to CANCELING.
12:37:07.084 [Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-4, groupId=flink-test] Received user wakeup
12:37:07.084 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-4, groupId=flink-test] Raising WakeupException in response to user wakeup
12:37:07.084 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (6/8) (d741c56af7d7897b7c9b50d823edfbe9) switched from RUNNING to CANCELING.
12:37:07.084 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Sending synchronous auto-commit of offsets {test-0=OffsetAndMetadata{offset=37, metadata=''}}
12:37:07.085 [Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-4, groupId=flink-test] Received user wakeup
12:37:07.085 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703).
12:37:07.085 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (7/8) (2997a1a27823bd12e6d4d30f3ed4ae07) switched from RUNNING to CANCELING.
12:37:07.085 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703) switched from RUNNING to CANCELING.
12:37:07.085 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (8/8) (1efbc7704f670524c1d8f2c35ba64a9c) switched from RUNNING to CANCELING.
12:37:07.086 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8) (428dc73df8de9b46f48fa46ac572c918) switched from RUNNING to CANCELING.
12:37:07.086 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703).
12:37:07.086 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8) (3c6afdb71460d036278bfbb10cb42882) switched from RUNNING to CANCELING.
12:37:07.086 [Source: Custom Source (1/2)] INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637) switched from CANCELING to CANCELED.
12:37:07.086 [Source: Custom Source (1/2)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637).
12:37:07.086 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Sink: Print to Std. Out (1/8) (9a3353529d19b6e60f77fdaf331ae33d).
12:37:07.086 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/8) (9a3353529d19b6e60f77fdaf331ae33d) switched from RUNNING to CANCELING.
12:37:07.086 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8) (ac70b34279050f0bb566409e01d7c7d0) switched from RUNNING to CANCELING.
12:37:07.086 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Source: Custom Source (1/2) from network environment (state: CANCELED).
12:37:07.087 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8) (81822fcb846c5fae6cbfb2f38a946f78) switched from RUNNING to CANCELING.
12:37:07.087 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Sink: Print to Std. Out (1/8) (9a3353529d19b6e60f77fdaf331ae33d).
12:37:07.087 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8) (88781f7e63abcf7c45a7adbe4717fb70) switched from RUNNING to CANCELING.
12:37:07.087 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flink-test] Committed offset 37 for partition test-0
12:37:07.087 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8) (9ce53d77a0ee6a17eb9b8276522cd7e7) switched from RUNNING to CANCELING.
12:37:07.087 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Sink: Print to Std. Out (2/8) (9c35784f2b94203761e88741e589c808).
12:37:07.087 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (2/8) (9c35784f2b94203761e88741e589c808) switched from RUNNING to CANCELING.
12:37:07.087 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8) (dc8b0d5ea7064d06e6fe27a7831258ef) switched from RUNNING to CANCELING.
12:37:07.088 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Sink: Print to Std. Out (2/8) (9c35784f2b94203761e88741e589c808).
12:37:07.089 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Sink: Print to Std. Out (3/8) (0f3a0ec033281cc7e0a745c8f6c3c01f).
12:37:07.089 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (3/8) (0f3a0ec033281cc7e0a745c8f6c3c01f) switched from RUNNING to CANCELING.
12:37:07.089 [Canceler for Sink: Print to Std. Out (2/8) (9c35784f2b94203761e88741e589c808).] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Sink: Print to Std. Out (2/8) (9c35784f2b94203761e88741e589c808): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@469c32d8.
12:37:07.089 [Canceler for Sink: Print to Std. Out (2/8) (9c35784f2b94203761e88741e589c808).] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition - ResultPartition a00ce70eba13e3e61a52a75474efa87f@bcef77c1d6a9777e909a0ae0592ad637 [PIPELINED_BOUNDED, 8 subpartitions, 7 pending references]: Received release notification for subpartition 1 (reference count now at: 7).
12:37:07.089 [Canceler for Sink: Print to Std. Out (2/8) (9c35784f2b94203761e88741e589c808).] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition - ResultPartition 7481ac5bf8655895bd5fc73e0e1fb082@5c92b8f60f982ce6ed1119e9dd227703 [PIPELINED_BOUNDED, 8 subpartitions, 7 pending references]: Received release notification for subpartition 1 (reference count now at: 7).
12:37:07.090 [Canceler for Sink: Print to Std. Out (1/8) (9a3353529d19b6e60f77fdaf331ae33d).] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Sink: Print to Std. Out (1/8) (9a3353529d19b6e60f77fdaf331ae33d): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@80c0fc0.
12:37:07.090 [Canceler for Sink: Print to Std. Out (1/8) (9a3353529d19b6e60f77fdaf331ae33d).] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition - ResultPartition a00ce70eba13e3e61a52a75474efa87f@bcef77c1d6a9777e909a0ae0592ad637 [PIPELINED_BOUNDED, 8 subpartitions, 6 pending references]: Received release notification for subpartition 0 (reference count now at: 6).
12:37:07.090 [Canceler for Sink: Print to Std. Out (1/8) (9a3353529d19b6e60f77fdaf331ae33d).] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition - ResultPartition 7481ac5bf8655895bd5fc73e0e1fb082@5c92b8f60f982ce6ed1119e9dd227703 [PIPELINED_BOUNDED, 8 subpartitions, 6 pending references]: Received release notification for subpartition 0 (reference count now at: 6).
12:37:07.091 [Sink: Print to Std. Out (2/8)] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (2/8) (9c35784f2b94203761e88741e589c808) switched from CANCELING to CANCELED.
12:37:07.091 [Sink: Print to Std. Out (2/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Sink: Print to Std. Out (2/8) (9c35784f2b94203761e88741e589c808).
12:37:07.091 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Sink: Print to Std. Out (3/8) (0f3a0ec033281cc7e0a745c8f6c3c01f).
12:37:07.091 [Sink: Print to Std. Out (2/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Sink: Print to Std. Out (2/8) from network environment (state: CANCELED).
12:37:07.091 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Releasing ResultPartition a00ce70eba13e3e61a52a75474efa87f@bcef77c1d6a9777e909a0ae0592ad637 [PIPELINED_BOUNDED, 8 subpartitions, 6 pending references].
12:37:07.091 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
12:37:07.091 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#0 [number of buffers: 2 (48348 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.091 [Canceler for Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703).] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-3, groupId=flink-test] Received user wakeup
12:37:07.091 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
12:37:07.091 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Sink: Print to Std. Out (4/8) (afd4b5e133e3f4b330525405bc11061f).
12:37:07.091 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (4/8) (afd4b5e133e3f4b330525405bc11061f) switched from RUNNING to CANCELING.
12:37:07.091 [Kafka 0.10 Fetcher for Source: Custom Source (2/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-3, groupId=flink-test] Sending synchronous auto-commit of offsets {}
12:37:07.092 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name successful-authentication:
12:37:07.091 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#1 [number of buffers: 2 (47853 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.092 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#2 [number of buffers: 2 (47853 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.092 [Sink: Print to Std. Out (1/8)] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (1/8) (9a3353529d19b6e60f77fdaf331ae33d) switched from CANCELING to CANCELED.
12:37:07.092 [Sink: Print to Std. Out (1/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Sink: Print to Std. Out (1/8) (9a3353529d19b6e60f77fdaf331ae33d).
12:37:07.092 [Sink: Print to Std. Out (1/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Sink: Print to Std. Out (1/8) from network environment (state: CANCELED).
12:37:07.092 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#3 [number of buffers: 2 (47985 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.092 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Sink: Print to Std. Out (4/8) (afd4b5e133e3f4b330525405bc11061f).
12:37:07.092 [Source: Custom Source (2/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-3, groupId=flink-test] Received user wakeup
12:37:07.092 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#4 [number of buffers: 2 (47952 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.092 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name failed-authentication:
12:37:07.092 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#5 [number of buffers: 2 (48051 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.093 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#6 [number of buffers: 2 (47839 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.093 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Sink: Print to Std. Out (5/8) (671f7f548d794ffcad3ccbfc64b30959).
12:37:07.093 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (5/8) (671f7f548d794ffcad3ccbfc64b30959) switched from RUNNING to CANCELING.
12:37:07.093 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#7 [number of buffers: 2 (47640 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.093 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
12:37:07.093 [Source: Custom Source (2/2)] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-3, groupId=flink-test] Received user wakeup
12:37:07.093 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Releasing ResultPartition c478dac72c53a389dd994de00ce05b8b@bcef77c1d6a9777e909a0ae0592ad637 [PIPELINED_BOUNDED, 8 subpartitions, 7 pending references].
12:37:07.094 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#0 [number of buffers: 2 (47853 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.094 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#1 [number of buffers: 2 (47919 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.094 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#2 [number of buffers: 2 (47820 bytes), number of buffers in backlog: 1, finished? false, read view? false].
12:37:07.094 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#3 [number of buffers: 2 (47787 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.094 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#4 [number of buffers: 2 (47589 bytes), number of buffers in backlog: 1, finished? false, read view? false].
12:37:07.094 [Canceler for Sink: Print to Std. Out (3/8) (0f3a0ec033281cc7e0a745c8f6c3c01f).] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Sink: Print to Std. Out (3/8) (0f3a0ec033281cc7e0a745c8f6c3c01f): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@689ac34c.
12:37:07.094 [Canceler for Sink: Print to Std. Out (3/8) (0f3a0ec033281cc7e0a745c8f6c3c01f).] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition - ResultPartition 7481ac5bf8655895bd5fc73e0e1fb082@5c92b8f60f982ce6ed1119e9dd227703 [PIPELINED_BOUNDED, 8 subpartitions, 5 pending references]: Received release notification for subpartition 2 (reference count now at: 5).
12:37:07.094 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#5 [number of buffers: 2 (47754 bytes), number of buffers in backlog: 1, finished? false, read view? false].
12:37:07.094 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Sink: Print to Std. Out (5/8) (671f7f548d794ffcad3ccbfc64b30959).
12:37:07.094 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#6 [number of buffers: 2 (48037 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.094 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637): Released PipelinedSubpartition#7 [number of buffers: 2 (47937 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.094 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
12:37:07.094 [Canceler for Sink: Print to Std. Out (4/8) (afd4b5e133e3f4b330525405bc11061f).] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Sink: Print to Std. Out (4/8) (afd4b5e133e3f4b330525405bc11061f): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@239e8c5.
12:37:07.094 [Canceler for Sink: Print to Std. Out (4/8) (afd4b5e133e3f4b330525405bc11061f).] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition - ResultPartition 7481ac5bf8655895bd5fc73e0e1fb082@5c92b8f60f982ce6ed1119e9dd227703 [PIPELINED_BOUNDED, 8 subpartitions, 4 pending references]: Received release notification for subpartition 3 (reference count now at: 4).
12:37:07.094 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Sink: Print to Std. Out (6/8) (d741c56af7d7897b7c9b50d823edfbe9).
12:37:07.094 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (6/8) (d741c56af7d7897b7c9b50d823edfbe9) switched from RUNNING to CANCELING.
12:37:07.094 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
12:37:07.094 [Sink: Print to Std. Out (3/8)] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (3/8) (0f3a0ec033281cc7e0a745c8f6c3c01f) switched from CANCELING to CANCELED.
12:37:07.095 [Sink: Print to Std. Out (3/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Sink: Print to Std. Out (3/8) (0f3a0ec033281cc7e0a745c8f6c3c01f).
12:37:07.095 [Sink: Print to Std. Out (4/8)] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (4/8) (afd4b5e133e3f4b330525405bc11061f) switched from CANCELING to CANCELED.
12:37:07.095 [Sink: Print to Std. Out (4/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Sink: Print to Std. Out (4/8) (afd4b5e133e3f4b330525405bc11061f).
12:37:07.095 [Sink: Print to Std. Out (4/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Sink: Print to Std. Out (4/8) from network environment (state: CANCELED).
12:37:07.095 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Sink: Print to Std. Out (6/8) (d741c56af7d7897b7c9b50d823edfbe9).
12:37:07.095 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
12:37:07.095 [Source: Custom Source (2/2)] INFO org.apache.flink.runtime.taskmanager.Task - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703) switched from CANCELING to CANCELED.
12:37:07.095 [Source: Custom Source (2/2)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703).
12:37:07.095 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Source: Custom Source (2/2) from network environment (state: CANCELED).
12:37:07.095 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
12:37:07.095 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Sink: Print to Std. Out (7/8) (2997a1a27823bd12e6d4d30f3ed4ae07).
12:37:07.095 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (7/8) (2997a1a27823bd12e6d4d30f3ed4ae07) switched from RUNNING to CANCELING.
12:37:07.095 [Sink: Print to Std. Out (3/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Sink: Print to Std. Out (3/8) from network environment (state: CANCELED).
12:37:07.095 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
12:37:07.095 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Sink: Print to Std. Out (7/8) (2997a1a27823bd12e6d4d30f3ed4ae07).
12:37:07.095 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by bcef77c1d6a9777e909a0ae0592ad637.
12:37:07.096 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
12:37:07.096 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering a00ce70eba13e3e61a52a75474efa87f@bcef77c1d6a9777e909a0ae0592ad637
12:37:07.096 [Source: Custom Source (1/2)] DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering c478dac72c53a389dd994de00ce05b8b@bcef77c1d6a9777e909a0ae0592ad637
12:37:07.096 [Source: Custom Source (1/2)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637) [CANCELED]
12:37:07.096 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
12:37:07.096 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Sink: Print to Std. Out (8/8) (1efbc7704f670524c1d8f2c35ba64a9c).
12:37:07.096 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (8/8) (1efbc7704f670524c1d8f2c35ba64a9c) switched from RUNNING to CANCELING.
12:37:07.096 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Sink: Print to Std. Out (8/8) (1efbc7704f670524c1d8f2c35ba64a9c).
12:37:07.096 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-0.bytes-sent
12:37:07.097 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-0.bytes-received
12:37:07.097 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8) (428dc73df8de9b46f48fa46ac572c918).
12:37:07.097 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8) (428dc73df8de9b46f48fa46ac572c918) switched from RUNNING to CANCELING.
12:37:07.097 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-0.latency
12:37:07.097 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8) (428dc73df8de9b46f48fa46ac572c918).
12:37:07.097 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-sent
12:37:07.097 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8) (3c6afdb71460d036278bfbb10cb42882).
12:37:07.097 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8) (3c6afdb71460d036278bfbb10cb42882) switched from RUNNING to CANCELING.
12:37:07.097 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.bytes-received
12:37:07.097 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-2147483647.latency
12:37:07.098 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8) (3c6afdb71460d036278bfbb10cb42882).
12:37:07.098 [Sink: Print to Std. Out (3/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by 0f3a0ec033281cc7e0a745c8f6c3c01f.
12:37:07.098 [Kafka 0.10 Fetcher for Source: Custom Source (1/2)] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-4, groupId=flink-test] Kafka consumer has been closed
12:37:07.098 [Sink: Print to Std. Out (3/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Sink: Print to Std. Out (3/8) (0f3a0ec033281cc7e0a745c8f6c3c01f) [CANCELED]
12:37:07.098 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Releasing ResultPartition 8e679901eefd2a043115970b09fcd8ec@5c92b8f60f982ce6ed1119e9dd227703 [PIPELINED_BOUNDED, 8 subpartitions, 7 pending references].
12:37:07.098 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#0 [number of buffers: 1 (702 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.098 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8) (ac70b34279050f0bb566409e01d7c7d0).
12:37:07.098 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8) (ac70b34279050f0bb566409e01d7c7d0) switched from RUNNING to CANCELING.
12:37:07.098 [Kafka 0.10 Fetcher for Source: Custom Source (2/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
12:37:07.100 [Kafka 0.10 Fetcher for Source: Custom Source (2/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
12:37:07.100 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8) (ac70b34279050f0bb566409e01d7c7d0).
12:37:07.100 [Kafka 0.10 Fetcher for Source: Custom Source (2/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name successful-authentication:
12:37:07.101 [Kafka 0.10 Fetcher for Source: Custom Source (2/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name failed-authentication:
12:37:07.101 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8) (81822fcb846c5fae6cbfb2f38a946f78).
12:37:07.101 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8) (81822fcb846c5fae6cbfb2f38a946f78) switched from RUNNING to CANCELING.
12:37:07.101 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][r:r]: 382 bytes read
12:37:07.098 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#1 [number of buffers: 1 (603 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.101 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 << "HTTP/1.1 200 OK[\r][\n]"
12:37:07.101 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#2 [number of buffers: 1 (1065 bytes), number of buffers in backlog: 1, finished? false, read view? false].
12:37:07.101 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 << "Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."[\r][\n]"
12:37:07.101 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#3 [number of buffers: 1 (735 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.101 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 << "content-type: application/json; charset=UTF-8[\r][\n]"
12:37:07.101 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 << "content-length: 186[\r][\n]"
12:37:07.101 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 << "[\r][\n]"
12:37:07.101 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#4 [number of buffers: 1 (1362 bytes), number of buffers in backlog: 1, finished? false, read view? false].
12:37:07.101 [Kafka 0.10 Fetcher for Source: Custom Source (2/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
12:37:07.101 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8) (81822fcb846c5fae6cbfb2f38a946f78).
12:37:07.101 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#5 [number of buffers: 1 (603 bytes), number of buffers in backlog: 1, finished? false, read view? false].
12:37:07.101 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#6 [number of buffers: 1 (867 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.101 [I/O dispatcher 25] DEBUG org.apache.http.wire - http-outgoing-6 << "{"took":86,"errors":false,"items":[{"update":{"_index":"test_index","_type":"_doc","_id":"e","_version":5,"result":"noop","_shards":{"total":2,"successful":2,"failed":0},"status":200}}]}"
12:37:07.101 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#7 [number of buffers: 1 (900 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.101 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Releasing ResultPartition 7481ac5bf8655895bd5fc73e0e1fb082@5c92b8f60f982ce6ed1119e9dd227703 [PIPELINED_BOUNDED, 8 subpartitions, 4 pending references].
12:37:07.101 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#0 [number of buffers: 1 (636 bytes), number of buffers in backlog: 1, finished? false, read view? false].
12:37:07.101 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#1 [number of buffers: 1 (834 bytes), number of buffers in backlog: 1, finished? false, read view? false].
12:37:07.101 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 << HTTP/1.1 200 OK
12:37:07.101 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 << Warning: 299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."
12:37:07.101 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 << content-type: application/json; charset=UTF-8
12:37:07.101 [I/O dispatcher 25] DEBUG org.apache.http.headers - http-outgoing-6 << content-length: 186
12:37:07.101 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [ACTIVE(186)] Response received
12:37:07.101 [Canceler for Sink: Print to Std. Out (5/8) (671f7f548d794ffcad3ccbfc64b30959).] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Sink: Print to Std. Out (5/8) (671f7f548d794ffcad3ccbfc64b30959): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@49f8c3ee.
12:37:07.101 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Discarding the results produced by task execution 4835c6c99eeb1c88e9349fda2b9ee046.
12:37:07.101 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 36] Response received HTTP/1.1 200 OK
12:37:07.101 [Canceler for Sink: Print to Std. Out (6/8) (d741c56af7d7897b7c9b50d823edfbe9).] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Sink: Print to Std. Out (6/8) (d741c56af7d7897b7c9b50d823edfbe9): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@1741910c.
12:37:07.102 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [ACTIVE(186)] Input ready
12:37:07.102 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 36] Consume content
12:37:07.102 [Kafka 0.10 Fetcher for Source: Custom Source (2/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
12:37:07.102 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 36] Connection can be kept alive indefinitely
12:37:07.102 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.MainClientExec - [exchange: 36] Response processed
12:37:07.102 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 36] releasing connection
12:37:07.103 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][r:r]: Remove attribute http.nio.exchange-handler
12:37:07.103 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-6][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 1 of 10; total allocated: 1 of 30]
12:37:07.103 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection [id: http-outgoing-6][route: {}->http://127.0.0.1:9200] can be kept alive indefinitely
12:37:07.103 [Sink: Print to Std. Out (6/8)] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (6/8) (d741c56af7d7897b7c9b50d823edfbe9) switched from CANCELING to CANCELED.
12:37:07.103 [Sink: Print to Std. Out (5/8)] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (5/8) (671f7f548d794ffcad3ccbfc64b30959) switched from CANCELING to CANCELED.
12:37:07.101 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#2 [number of buffers: 1 (537 bytes), number of buffers in backlog: 1, finished? false, read view? false].
12:37:07.103 [Sink: Print to Std. Out (5/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Sink: Print to Std. Out (5/8) (671f7f548d794ffcad3ccbfc64b30959).
12:37:07.103 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][r:r]: Set timeout 0
12:37:07.103 [Sink: Print to Std. Out (5/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Sink: Print to Std. Out (5/8) from network environment (state: CANCELED).
12:37:07.103 [Sink: Print to Std. Out (6/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Sink: Print to Std. Out (6/8) (d741c56af7d7897b7c9b50d823edfbe9).
12:37:07.103 [Sink: Print to Std. Out (6/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Sink: Print to Std. Out (6/8) from network environment (state: CANCELED).
12:37:07.103 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-6][route: {}->http://127.0.0.1:9200][total kept alive: 1; route allocated: 1 of 10; total allocated: 1 of 30]
12:37:07.103 [I/O dispatcher 25] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned [HTTP/1.1 200 OK]
12:37:07.103 [Kafka 0.10 Fetcher for Source: Custom Source (2/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
12:37:07.103 [I/O dispatcher 25] WARN org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.3.1-4749ba6 "[types removal] Specifying types in bulk requests is deprecated."]
12:37:07.103 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#3 [number of buffers: 1 (867 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.103 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#4 [number of buffers: 1 (966 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.103 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#5 [number of buffers: 1 (999 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.104 [Canceler for Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8) (3c6afdb71460d036278bfbb10cb42882).] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8) (3c6afdb71460d036278bfbb10cb42882): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@35acd20.
12:37:07.104 [Canceler for Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8) (428dc73df8de9b46f48fa46ac572c918).] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8) (428dc73df8de9b46f48fa46ac572c918): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@7e75e833.
12:37:07.104 [Kafka 0.10 Fetcher for Source: Custom Source (2/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
12:37:07.104 [Kafka 0.10 Fetcher for Source: Custom Source (2/2)] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
12:37:07.104 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{d02af1e37f0ee6aa4567838ebad19f94}] because: Slot is being returned to the SlotPool.
12:37:07.104 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [ACTIVE] [content length: 186; pos: 186; completed: true]
12:37:07.104 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager is shutting down
12:37:07.104 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#6 [number of buffers: 1 (636 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.104 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-7 127.0.0.1:53912<->127.0.0.1:9200[ACTIVE][r:r]: Close
12:37:07.104 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.PipelinedSubpartition - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703): Released PipelinedSubpartition#7 [number of buffers: 1 (603 bytes), number of buffers in backlog: 0, finished? false, read view? false].
12:37:07.104 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager is shutting down
12:37:07.105 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-4 127.0.0.1:53916<->127.0.0.1:9200[ACTIVE][r:r]: Close
12:37:07.105 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by 5c92b8f60f982ce6ed1119e9dd227703.
12:37:07.105 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering 7481ac5bf8655895bd5fc73e0e1fb082@5c92b8f60f982ce6ed1119e9dd227703
12:37:07.105 [Source: Custom Source (2/2)] DEBUG org.apache.flink.runtime.io.network.TaskEventDispatcher - unregistering 8e679901eefd2a043115970b09fcd8ec@5c92b8f60f982ce6ed1119e9dd227703
12:37:07.105 [Kafka 0.10 Fetcher for Source: Custom Source (2/2)] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-3, groupId=flink-test] Kafka consumer has been closed
12:37:07.105 [Source: Custom Source (2/2)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703) [CANCELED]
12:37:07.105 [flink-akka.actor.default-dispatcher-128] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by 4835c6c99eeb1c88e9349fda2b9ee046.
12:37:07.106 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8) (88781f7e63abcf7c45a7adbe4717fb70).
12:37:07.106 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8) (88781f7e63abcf7c45a7adbe4717fb70) switched from RUNNING to CANCELING.
12:37:07.106 [I/O dispatcher 33] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-7 [CLOSED]: Disconnected
12:37:07.106 [Sink: Print to Std. Out (4/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by afd4b5e133e3f4b330525405bc11061f.
12:37:07.108 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8) (88781f7e63abcf7c45a7adbe4717fb70).
12:37:07.106 [I/O dispatcher 41] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-4 [CLOSED]: Disconnected
12:37:07.108 [Sink: Print to Std. Out (4/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Sink: Print to Std. Out (4/8) (afd4b5e133e3f4b330525405bc11061f) [CANCELED]
12:37:07.108 [Sink: Print to Std. Out (1/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by 9a3353529d19b6e60f77fdaf331ae33d.
12:37:07.108 [Sink: Print to Std. Out (1/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Sink: Print to Std. Out (1/8) (9a3353529d19b6e60f77fdaf331ae33d) [CANCELED]
12:37:07.108 [Sink: Print to Std. Out (2/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by 9c35784f2b94203761e88741e589c808.
12:37:07.108 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager shut down
12:37:07.108 [Sink: Print to Std. Out (2/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Sink: Print to Std. Out (2/8) (9c35784f2b94203761e88741e589c808) [CANCELED]
12:37:07.108 [Canceler for Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8) (81822fcb846c5fae6cbfb2f38a946f78).] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8) (81822fcb846c5fae6cbfb2f38a946f78): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@e0cae7c.
12:37:07.109 [Sink: Print to Std. Out (6/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by d741c56af7d7897b7c9b50d823edfbe9.
12:37:07.109 [Sink: Print to Std. Out (6/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Sink: Print to Std. Out (6/8) (d741c56af7d7897b7c9b50d823edfbe9) [CANCELED]
12:37:07.109 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager is shutting down
12:37:07.109 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager is shutting down
12:37:07.109 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-2 127.0.0.1:53911<->127.0.0.1:9200[ACTIVE][r:r]: Close
12:37:07.109 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-6 127.0.0.1:53915<->127.0.0.1:9200[ACTIVE][r:r]: Close
12:37:07.109 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager shut down
12:37:07.109 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8) (428dc73df8de9b46f48fa46ac572c918) switched from CANCELING to CANCELED.
12:37:07.109 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8) (428dc73df8de9b46f48fa46ac572c918).
12:37:07.109 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8) from network environment (state: CANCELED).
12:37:07.110 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by 428dc73df8de9b46f48fa46ac572c918.
12:37:07.110 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8) (428dc73df8de9b46f48fa46ac572c918) [CANCELED]
12:37:07.110 [I/O dispatcher 9] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-2 [CLOSED]: Disconnected
12:37:07.110 [I/O dispatcher 25] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-6 [CLOSING]: Disconnected
12:37:07.111 [Sink: Print to Std. Out (5/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by 671f7f548d794ffcad3ccbfc64b30959.
12:37:07.111 [Sink: Print to Std. Out (5/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Sink: Print to Std. Out (5/8) (671f7f548d794ffcad3ccbfc64b30959) [CANCELED]
12:37:07.113 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager shut down
12:37:07.113 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8) (9ce53d77a0ee6a17eb9b8276522cd7e7).
12:37:07.113 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8) (9ce53d77a0ee6a17eb9b8276522cd7e7) switched from RUNNING to CANCELING.
12:37:07.114 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8) (9ce53d77a0ee6a17eb9b8276522cd7e7).
12:37:07.114 [Canceler for Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8) (88781f7e63abcf7c45a7adbe4717fb70).] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8) (88781f7e63abcf7c45a7adbe4717fb70): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@6ced0182.
12:37:07.114 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] ERROR org.apache.flink.streaming.runtime.tasks.StreamTask - Error during disposal of stream operator.
java.lang.RuntimeException: An error occurred in ElasticsearchSink.
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.checkErrorAndRethrow(ElasticsearchSinkBase.java:379)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.close(ElasticsearchSinkBase.java:341)
	at org.apache.flink.api.common.functions.util.FunctionUtils.closeFunction(FunctionUtils.java:43)
	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.dispose(AbstractUdfStreamOperator.java:117)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.disposeAllOperators(StreamTask.java:477)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:378)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.elasticsearch.ElasticsearchException: Elasticsearch exception [type=version_conflict_engine_exception, reason=[e]: version conflict, required seqNo [14], primary term [1]. current document has seqNo [16] and primary term [1]]
	at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:509)
	at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:420)
	at org.elasticsearch.action.bulk.BulkItemResponse.fromXContent(BulkItemResponse.java:135)
	at org.elasticsearch.action.bulk.BulkResponse.fromXContent(BulkResponse.java:198)
	at org.elasticsearch.client.RestHighLevelClient.parseEntity(RestHighLevelClient.java:1406)
	at org.elasticsearch.client.RestHighLevelClient.lambda$performRequestAsyncAndParseEntity$10(RestHighLevelClient.java:1284)
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:1334)
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:836)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:538)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:529)
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122)
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338)
	at org.apache.http.impl.nio.client.InternalRequestExecutor.inputReady(InternalRequestExecutor.java:83)
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591)
	... 1 common frames omitted
12:37:07.114 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8) (81822fcb846c5fae6cbfb2f38a946f78) switched from CANCELING to CANCELED.
12:37:07.114 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8) (81822fcb846c5fae6cbfb2f38a946f78).
12:37:07.115 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8) from network environment (state: CANCELED).
12:37:07.115 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by 81822fcb846c5fae6cbfb2f38a946f78.
12:37:07.115 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8) (81822fcb846c5fae6cbfb2f38a946f78) [CANCELED]
12:37:07.115 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Attempting to cancel task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8) (dc8b0d5ea7064d06e6fe27a7831258ef).
12:37:07.115 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8) (dc8b0d5ea7064d06e6fe27a7831258ef) switched from RUNNING to CANCELING.
12:37:07.115 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskmanager.Task - Triggering cancellation of task code Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8) (dc8b0d5ea7064d06e6fe27a7831258ef).
12:37:07.116 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager shut down
12:37:07.116 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8) (ac70b34279050f0bb566409e01d7c7d0) switched from CANCELING to CANCELED.
12:37:07.116 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8) (ac70b34279050f0bb566409e01d7c7d0).
12:37:07.116 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8) from network environment (state: CANCELED).
12:37:07.116 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by ac70b34279050f0bb566409e01d7c7d0.
12:37:07.116 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8) (ac70b34279050f0bb566409e01d7c7d0): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@78b91c7f.
12:37:07.116 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] ERROR org.apache.flink.streaming.runtime.tasks.StreamTask - Error during disposal of stream operator.
java.lang.RuntimeException: An error occurred in ElasticsearchSink.
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.checkErrorAndRethrow(ElasticsearchSinkBase.java:379)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.close(ElasticsearchSinkBase.java:341)
	at org.apache.flink.api.common.functions.util.FunctionUtils.closeFunction(FunctionUtils.java:43)
	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.dispose(AbstractUdfStreamOperator.java:117)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.disposeAllOperators(StreamTask.java:477)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:378)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.elasticsearch.ElasticsearchException: Elasticsearch exception [type=version_conflict_engine_exception, reason=[d]: version conflict, required seqNo [12], primary term [1]. current document has seqNo [15] and primary term [1]]
	at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:509)
	at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:420)
	at org.elasticsearch.action.bulk.BulkItemResponse.fromXContent(BulkItemResponse.java:135)
	at org.elasticsearch.action.bulk.BulkResponse.fromXContent(BulkResponse.java:198)
	at org.elasticsearch.client.RestHighLevelClient.parseEntity(RestHighLevelClient.java:1406)
	at org.elasticsearch.client.RestHighLevelClient.lambda$performRequestAsyncAndParseEntity$10(RestHighLevelClient.java:1284)
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:1334)
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:836)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:538)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:529)
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122)
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338)
	at org.apache.http.impl.nio.client.InternalRequestExecutor.inputReady(InternalRequestExecutor.java:83)
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591)
	... 1 common frames omitted
12:37:07.116 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8) (3c6afdb71460d036278bfbb10cb42882) switched from CANCELING to CANCELED.
12:37:07.116 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8) (3c6afdb71460d036278bfbb10cb42882).
12:37:07.116 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8) from network environment (state: CANCELED).
12:37:07.116 [Canceler for Sink: Print to Std. Out (7/8) (2997a1a27823bd12e6d4d30f3ed4ae07).] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Sink: Print to Std. Out (7/8) (2997a1a27823bd12e6d4d30f3ed4ae07): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@38f4be33.
12:37:07.117 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by 3c6afdb71460d036278bfbb10cb42882.
12:37:07.117 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8) (3c6afdb71460d036278bfbb10cb42882) [CANCELED]
12:37:07.116 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8) (ac70b34279050f0bb566409e01d7c7d0) [CANCELED]
12:37:07.117 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source bcef77c1d6a9777e909a0ae0592ad637.
12:37:07.117 [Sink: Print to Std. Out (7/8)] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (7/8) (2997a1a27823bd12e6d4d30f3ed4ae07) switched from CANCELING to CANCELED.
12:37:07.117 [Sink: Print to Std. Out (7/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Sink: Print to Std. Out (7/8) (2997a1a27823bd12e6d4d30f3ed4ae07).
12:37:07.117 [Sink: Print to Std. Out (7/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Sink: Print to Std. Out (7/8) from network environment (state: CANCELED).
12:37:07.117 [Sink: Print to Std. Out (7/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by 2997a1a27823bd12e6d4d30f3ed4ae07.
12:37:07.117 [Sink: Print to Std. Out (7/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Sink: Print to Std. Out (7/8) (2997a1a27823bd12e6d4d30f3ed4ae07) [CANCELED]
12:37:07.118 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Sink: Print to Std. Out 0f3a0ec033281cc7e0a745c8f6c3c01f.
12:37:07.118 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source 5c92b8f60f982ce6ed1119e9dd227703.
12:37:07.118 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Sink: Print to Std. Out afd4b5e133e3f4b330525405bc11061f.
12:37:07.118 [Canceler for Sink: Print to Std. Out (8/8) (1efbc7704f670524c1d8f2c35ba64a9c).] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Sink: Print to Std. Out (8/8) (1efbc7704f670524c1d8f2c35ba64a9c): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@3b86e9b4.
12:37:07.120 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Sink: Print to Std. Out 9a3353529d19b6e60f77fdaf331ae33d.
12:37:07.121 [Sink: Print to Std. Out (8/8)] INFO org.apache.flink.runtime.taskmanager.Task - Sink: Print to Std. Out (8/8) (1efbc7704f670524c1d8f2c35ba64a9c) switched from CANCELING to CANCELED.
12:37:07.121 [Sink: Print to Std. Out (8/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Sink: Print to Std. Out (8/8) (1efbc7704f670524c1d8f2c35ba64a9c).
12:37:07.121 [Sink: Print to Std. Out (8/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Sink: Print to Std. Out (8/8) from network environment (state: CANCELED).
12:37:07.121 [Sink: Print to Std. Out (8/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by 1efbc7704f670524c1d8f2c35ba64a9c.
12:37:07.121 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Sink: Print to Std. Out 9c35784f2b94203761e88741e589c808.
12:37:07.121 [Sink: Print to Std. Out (8/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Sink: Print to Std. Out (8/8) (1efbc7704f670524c1d8f2c35ba64a9c) [CANCELED]
12:37:07.121 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Sink: Print to Std. Out d741c56af7d7897b7c9b50d823edfbe9.
12:37:07.121 [Canceler for Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8) (dc8b0d5ea7064d06e6fe27a7831258ef).] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8) (dc8b0d5ea7064d06e6fe27a7831258ef): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@5e446156.
12:37:07.121 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source (1/2) (bcef77c1d6a9777e909a0ae0592ad637) switched from CANCELING to CANCELED.
12:37:07.121 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) 428dc73df8de9b46f48fa46ac572c918.
12:37:07.121 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Source: Custom Source (1/2) - execution #0 to FAILED while being CANCELED.
12:37:07.121 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Sink: Print to Std. Out 671f7f548d794ffcad3ccbfc64b30959.
12:37:07.121 [Canceler for Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8) (9ce53d77a0ee6a17eb9b8276522cd7e7).] DEBUG org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8) (9ce53d77a0ee6a17eb9b8276522cd7e7): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@47f1dd3e.
12:37:07.122 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager is shutting down
12:37:07.122 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) 81822fcb846c5fae6cbfb2f38a946f78.
12:37:07.122 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-5 127.0.0.1:53909<->127.0.0.1:9200[ACTIVE][r:r]: Close
12:37:07.122 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) 3c6afdb71460d036278bfbb10cb42882.
12:37:07.122 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager is shutting down
12:37:07.122 [I/O dispatcher 17] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-5 [CLOSED]: Disconnected
12:37:07.122 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-1 127.0.0.1:53914<->127.0.0.1:9200[ACTIVE][r:r]: Close
12:37:07.122 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) ac70b34279050f0bb566409e01d7c7d0.
12:37:07.124 [I/O dispatcher 49] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-1 [CLOSED]: Disconnected
12:37:07.123 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{e0c179f0ffecd2c8ae1bd16c690b19f1}] because: Slot is being returned to the SlotPool.
12:37:07.124 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (3/8) (0f3a0ec033281cc7e0a745c8f6c3c01f) switched from CANCELING to CANCELED.
12:37:07.124 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Sink: Print to Std. Out (3/8) - execution #0 to FAILED while being CANCELED.
12:37:07.125 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager shut down
12:37:07.125 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8) (dc8b0d5ea7064d06e6fe27a7831258ef) switched from CANCELING to CANCELED.
12:37:07.125 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8) (dc8b0d5ea7064d06e6fe27a7831258ef).
12:37:07.125 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8) from network environment (state: CANCELED).
12:37:07.126 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by dc8b0d5ea7064d06e6fe27a7831258ef.
12:37:07.126 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8) (dc8b0d5ea7064d06e6fe27a7831258ef) [CANCELED]
12:37:07.126 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Sink: Print to Std. Out 2997a1a27823bd12e6d4d30f3ed4ae07.
12:37:07.127 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Sink: Print to Std. Out 1efbc7704f670524c1d8f2c35ba64a9c.
12:37:07.127 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) dc8b0d5ea7064d06e6fe27a7831258ef.
12:37:07.127 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{8025cceab9f3884a0d5456814df81e66}] because: Slot is being returned to the SlotPool.
12:37:07.127 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source (2/2) (5c92b8f60f982ce6ed1119e9dd227703) switched from CANCELING to CANCELED.
12:37:07.127 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Source: Custom Source (2/2) - execution #0 to FAILED while being CANCELED.
12:37:07.128 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{d1004d46846551a3e0a4eb2f4bbfc390}] because: Slot is being returned to the SlotPool.
12:37:07.128 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager shut down
12:37:07.128 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (4/8) (afd4b5e133e3f4b330525405bc11061f) switched from CANCELING to CANCELED.
12:37:07.128 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8) (9ce53d77a0ee6a17eb9b8276522cd7e7) switched from CANCELING to CANCELED.
12:37:07.128 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Sink: Print to Std. Out (4/8) - execution #0 to FAILED while being CANCELED.
12:37:07.128 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8) (9ce53d77a0ee6a17eb9b8276522cd7e7).
12:37:07.128 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8) from network environment (state: CANCELED).
12:37:07.128 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by 9ce53d77a0ee6a17eb9b8276522cd7e7.
12:37:07.128 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8) (9ce53d77a0ee6a17eb9b8276522cd7e7) [CANCELED]
12:37:07.129 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{c5bc5ddca88560402317a675a5a740fe}] because: Slot is being returned to the SlotPool.
12:37:07.129 [flink-akka.actor.default-dispatcher-133] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) 9ce53d77a0ee6a17eb9b8276522cd7e7.
12:37:07.129 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (1/8) (9a3353529d19b6e60f77fdaf331ae33d) switched from CANCELING to CANCELED.
12:37:07.129 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Sink: Print to Std. Out (1/8) - execution #0 to FAILED while being CANCELED.
12:37:07.130 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{1e5b625ce20ac8dc690d8eda331f1df9}] because: Slot is being returned to the SlotPool.
12:37:07.130 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{67a6754dd39c86e1c29ff920a1ef76b2}] because: Release multi task slot because all children have been released.
12:37:07.130 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (2/8) (9c35784f2b94203761e88741e589c808) switched from CANCELING to CANCELED.
12:37:07.130 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Sink: Print to Std. Out (2/8) - execution #0 to FAILED while being CANCELED.
12:37:07.130 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Adding returned slot [AllocationID{05edcf935db937ae387c68dced2a94e4}] to available slots
12:37:07.130 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (6/8) (d741c56af7d7897b7c9b50d823edfbe9) switched from CANCELING to CANCELED.
12:37:07.131 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Sink: Print to Std. Out (6/8) - execution #0 to FAILED while being CANCELED.
12:37:07.131 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{ebd1ead0866ead21574aca31c67c747f}] because: Slot is being returned to the SlotPool.
12:37:07.131 [flink-akka.actor.default-dispatcher-128] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{059e4f0b8f1b473557a10a2262c988e3}] because: Slot is being returned to the SlotPool.
12:37:07.132 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8) (428dc73df8de9b46f48fa46ac572c918) switched from CANCELING to CANCELED.
12:37:07.132 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (1/8) - execution #0 to FAILED while being CANCELED.
12:37:07.132 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] INFO org.elasticsearch.action.bulk.BulkRequestHandler - Bulk request 4 has been cancelled.
java.lang.InterruptedException: null
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1040)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1345)
	at java.base/java.util.concurrent.CountDownLatch.await(CountDownLatch.java:232)
	at org.elasticsearch.action.bulk.BulkRequestHandler.execute(BulkRequestHandler.java:86)
	at org.elasticsearch.action.bulk.BulkProcessor.execute(BulkProcessor.java:339)
	at org.elasticsearch.action.bulk.BulkProcessor.executeIfNeeded(BulkProcessor.java:330)
	at org.elasticsearch.action.bulk.BulkProcessor.internalAdd(BulkProcessor.java:288)
	at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:271)
	at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:267)
	at org.apache.flink.streaming.connectors.elasticsearch6.Elasticsearch6BulkProcessorIndexer.add(Elasticsearch6BulkProcessorIndexer.java:82)
	at connector.es.EsConnectorDemo$2.process(EsConnectorDemo.java:90)
	at connector.es.EsConnectorDemo$2.process(EsConnectorDemo.java:69)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.invoke(ElasticsearchSinkBase.java:306)
	at org.apache.flink.streaming.api.functions.sink.SinkFunction.invoke(SinkFunction.java:52)
	at org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:56)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:649)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:602)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamFilter.processElement(StreamFilter.java:40)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:202)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:105)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:300)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.base/java.lang.Thread.run(Thread.java:834)
12:37:07.132 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{c6272dda20c38c60e4cb4b851ae47502}] because: Slot is being returned to the SlotPool.
12:37:07.132 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{b1184ccf75ed3811528066775a34df21}] because: Release multi task slot because all children have been released.
12:37:07.132 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Adding returned slot [AllocationID{f13cb848b24e3e3e8e733b16004e062c}] to available slots
12:37:07.132 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (5/8) (671f7f548d794ffcad3ccbfc64b30959) switched from CANCELING to CANCELED.
12:37:07.132 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Sink: Print to Std. Out (5/8) - execution #0 to FAILED while being CANCELED.
12:37:07.132 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] ERROR org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase - Failed Elasticsearch bulk request: null
12:37:07.132 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{cd59fc4a81fd193d1af36e48cbad1ef3}] because: Slot is being returned to the SlotPool.
12:37:07.133 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8) (81822fcb846c5fae6cbfb2f38a946f78) switched from CANCELING to CANCELED.
12:37:07.133 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager is shutting down
12:37:07.133 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 127.0.0.1:53910<->127.0.0.1:9200[ACTIVE][r:w]: Close
12:37:07.133 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (4/8) - execution #0 to FAILED while being CANCELED.
12:37:07.133 [flink-akka.actor.default-dispatcher-128] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{6ae167cf815b656fd674e788559c727b}] because: Slot is being returned to the SlotPool.
12:37:07.133 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalIODispatch - http-outgoing-0 [CLOSED]: Disconnected
12:37:07.133 [flink-akka.actor.default-dispatcher-128] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{23fb6480c6d050fb7421929760796332}] because: Release multi task slot because all children have been released.
12:37:07.133 [flink-akka.actor.default-dispatcher-128] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Adding returned slot [AllocationID{c0b004201bfbe3400cc808c96d8b8365}] to available slots
12:37:07.134 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8) (3c6afdb71460d036278bfbb10cb42882) switched from CANCELING to CANCELED.
12:37:07.134 [I/O dispatcher 57] DEBUG org.elasticsearch.client.RestClient - request [POST http://127.0.0.1:9200/_bulk?timeout=1m] failed
org.apache.http.ConnectionClosedException: Connection closed unexpectedly
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.closed(HttpAsyncRequestExecutor.java:146)
	at org.apache.http.impl.nio.client.InternalRequestExecutor.closed(InternalRequestExecutor.java:64)
	at org.apache.http.impl.nio.client.InternalIODispatch.onClosed(InternalIODispatch.java:71)
	at org.apache.http.impl.nio.client.InternalIODispatch.onClosed(InternalIODispatch.java:39)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.disconnected(AbstractIODispatch.java:100)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.sessionClosed(BaseIOReactor.java:279)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processClosedSessions(AbstractIOReactor.java:440)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:283)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591)
	at java.base/java.lang.Thread.run(Thread.java:834)
12:37:07.134 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (2/8) - execution #0 to FAILED while being CANCELED.
12:37:07.135 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{22bb4d395a8619b6e56b5d48bed3861a}] because: Slot is being returned to the SlotPool.
12:37:07.135 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{44f4cbbbaf936a8acbeab99e3e6c5efb}] because: Release multi task slot because all children have been released.
12:37:07.135 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Adding returned slot [AllocationID{75e09d17a2942a3065f51a6840a482ff}] to available slots
12:37:07.135 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8) (ac70b34279050f0bb566409e01d7c7d0) switched from CANCELING to CANCELED.
12:37:07.135 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (3/8) - execution #0 to FAILED while being CANCELED.
12:37:07.135 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{5db2147f2943f269ab7f63fa2b365b20}] because: Slot is being returned to the SlotPool.
12:37:07.135 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{3e7bd6b7d6e68acec9696656a198d3a6}] because: Release multi task slot because all children have been released.
12:37:07.135 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Adding returned slot [AllocationID{ef1adb8c0f6b44c8d1fd7cf1c34e1b7d}] to available slots
12:37:07.135 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (7/8) (2997a1a27823bd12e6d4d30f3ed4ae07) switched from CANCELING to CANCELED.
12:37:07.136 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Sink: Print to Std. Out (7/8) - execution #0 to FAILED while being CANCELED.
12:37:07.136 [I/O dispatcher 57] DEBUG org.elasticsearch.client.RestClient - added [[host=http://127.0.0.1:9200]] to blacklist
12:37:07.136 [I/O dispatcher 57] ERROR org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase - Failed Elasticsearch bulk request: Connection closed unexpectedly
12:37:07.136 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{eb3f2c3195da229322e366bb5f054331}] because: Slot is being returned to the SlotPool.
12:37:07.136 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.ManagedNHttpClientConnectionImpl - http-outgoing-0 [CLOSED][]: Shutdown
12:37:07.136 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.client.InternalHttpAsyncClient - [exchange: 35] connection aborted
12:37:07.136 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Sink: Print to Std. Out (8/8) (1efbc7704f670524c1d8f2c35ba64a9c) switched from CANCELING to CANCELED.
12:37:07.136 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Sink: Print to Std. Out (8/8) - execution #0 to FAILED while being CANCELED.
12:37:07.137 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{295c6c46a79d94283fa95042835e7518}] because: Slot is being returned to the SlotPool.
12:37:07.137 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8) (dc8b0d5ea7064d06e6fe27a7831258ef) switched from CANCELING to CANCELED.
12:37:07.137 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (8/8) - execution #0 to FAILED while being CANCELED.
12:37:07.137 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8) (9ce53d77a0ee6a17eb9b8276522cd7e7) switched from CANCELING to CANCELED.
12:37:07.137 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (7/8) - execution #0 to FAILED while being CANCELED.
12:37:07.137 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{887aa3ffc53e7b6ba987097678262d04}] because: Slot is being returned to the SlotPool.
12:37:07.138 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{6715ab7ec90dcfc0995fb5a87f03d354}] because: Release multi task slot because all children have been released.
12:37:07.138 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Adding returned slot [AllocationID{9acab6076aac22871be5d350fba4ca31}] to available slots
12:37:07.138 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{290fa2ca328e03d0b82eea5f6f0d863f}] because: Slot is being returned to the SlotPool.
12:37:07.138 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{a63e244e13b46e0ec7cbe04c71b901dc}] because: Release multi task slot because all children have been released.
12:37:07.138 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Adding returned slot [AllocationID{e758aac1ee5da11a6e9011f3605acd4f}] to available slots
12:37:08.136 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection manager shut down
12:37:08.136 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Releasing connection: [id: http-outgoing-0][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 0 of 10; total allocated: 0 of 30]
12:37:08.136 [I/O dispatcher 57] DEBUG org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager - Connection released: [id: http-outgoing-0][route: {}->http://127.0.0.1:9200][total kept alive: 0; route allocated: 0 of 10; total allocated: 0 of 30]
12:37:08.137 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] ERROR org.apache.flink.streaming.runtime.tasks.StreamTask - Error during disposal of stream operator.
java.lang.RuntimeException: An error occurred in ElasticsearchSink.
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.checkErrorAndRethrow(ElasticsearchSinkBase.java:379)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.close(ElasticsearchSinkBase.java:341)
	at org.apache.flink.api.common.functions.util.FunctionUtils.closeFunction(FunctionUtils.java:43)
	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.dispose(AbstractUdfStreamOperator.java:117)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.disposeAllOperators(StreamTask.java:477)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:378)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.lang.InterruptedException: null
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1040)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1345)
	at java.base/java.util.concurrent.CountDownLatch.await(CountDownLatch.java:232)
	at org.elasticsearch.action.bulk.BulkRequestHandler.execute(BulkRequestHandler.java:86)
	at org.elasticsearch.action.bulk.BulkProcessor.execute(BulkProcessor.java:339)
	at org.elasticsearch.action.bulk.BulkProcessor.executeIfNeeded(BulkProcessor.java:330)
	at org.elasticsearch.action.bulk.BulkProcessor.internalAdd(BulkProcessor.java:288)
	at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:271)
	at org.elasticsearch.action.bulk.BulkProcessor.add(BulkProcessor.java:267)
	at org.apache.flink.streaming.connectors.elasticsearch6.Elasticsearch6BulkProcessorIndexer.add(Elasticsearch6BulkProcessorIndexer.java:82)
	at connector.es.EsConnectorDemo$2.process(EsConnectorDemo.java:90)
	at connector.es.EsConnectorDemo$2.process(EsConnectorDemo.java:69)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.invoke(ElasticsearchSinkBase.java:306)
	at org.apache.flink.streaming.api.functions.sink.SinkFunction.invoke(SinkFunction.java:52)
	at org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:56)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:649)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:602)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamFilter.processElement(StreamFilter.java:40)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:202)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:105)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:300)
	... 2 common frames omitted
12:37:08.138 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] INFO org.apache.flink.runtime.taskmanager.Task - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8) (88781f7e63abcf7c45a7adbe4717fb70) switched from CANCELING to CANCELED.
12:37:08.139 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] INFO org.apache.flink.runtime.taskmanager.Task - Freeing task resources for Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8) (88781f7e63abcf7c45a7adbe4717fb70).
12:37:08.139 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Unregister task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8) from network environment (state: CANCELED).
12:37:08.139 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Released all partitions produced by 88781f7e63abcf7c45a7adbe4717fb70.
12:37:08.140 [Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8)] INFO org.apache.flink.runtime.taskmanager.Task - Ensuring all FileSystem streams are closed for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8) (88781f7e63abcf7c45a7adbe4717fb70) [CANCELED]
12:37:08.141 [flink-akka.actor.default-dispatcher-132] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Un-registering task and sending final execution state CANCELED to JobManager for task Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) 88781f7e63abcf7c45a7adbe4717fb70.
12:37:08.146 [flink-akka.actor.default-dispatcher-133] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8) (88781f7e63abcf7c45a7adbe4717fb70) switched from CANCELING to CANCELED.
12:37:08.146 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Ignoring transition of vertex Map -> Filter -> (Sink: Print to Std. Out, Sink: Unnamed) (6/8) - execution #0 to FAILED while being CANCELED.
12:37:08.149 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{137314c001a9aa59f0514fb84a745561}] because: Slot is being returned to the SlotPool.
12:37:08.150 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.executiongraph.ExecutionGraph - Try to restart or fail the job this-test (0112c0387c891788cf37a4fab90f26d5) if no longer possible.
java.lang.RuntimeException: An error occurred in ElasticsearchSink.
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.checkErrorAndRethrow(ElasticsearchSinkBase.java:379)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.invoke(ElasticsearchSinkBase.java:304)
	at org.apache.flink.streaming.api.functions.sink.SinkFunction.invoke(SinkFunction.java:52)
	at org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:56)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:649)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:602)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamFilter.processElement(StreamFilter.java:40)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:202)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:105)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:300)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.elasticsearch.ElasticsearchException: Elasticsearch exception [type=version_conflict_engine_exception, reason=[e]: version conflict, required seqNo [8], primary term [1]. current document has seqNo [14] and primary term [1]]
	at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:509)
	at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:420)
	at org.elasticsearch.action.bulk.BulkItemResponse.fromXContent(BulkItemResponse.java:135)
	at org.elasticsearch.action.bulk.BulkResponse.fromXContent(BulkResponse.java:198)
	at org.elasticsearch.client.RestHighLevelClient.parseEntity(RestHighLevelClient.java:1406)
	at org.elasticsearch.client.RestHighLevelClient.lambda$performRequestAsyncAndParseEntity$10(RestHighLevelClient.java:1284)
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:1334)
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:836)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:538)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:529)
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122)
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338)
	at org.apache.http.impl.nio.client.InternalRequestExecutor.inputReady(InternalRequestExecutor.java:83)
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591)
	... 1 common frames omitted
12:37:08.151 [flink-akka.actor.default-dispatcher-132] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job this-test (0112c0387c891788cf37a4fab90f26d5) switched from state FAILING to FAILED.
java.lang.RuntimeException: An error occurred in ElasticsearchSink.
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.checkErrorAndRethrow(ElasticsearchSinkBase.java:379)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.invoke(ElasticsearchSinkBase.java:304)
	at org.apache.flink.streaming.api.functions.sink.SinkFunction.invoke(SinkFunction.java:52)
	at org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:56)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:649)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:602)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamFilter.processElement(StreamFilter.java:40)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:202)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:105)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:300)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.elasticsearch.ElasticsearchException: Elasticsearch exception [type=version_conflict_engine_exception, reason=[e]: version conflict, required seqNo [8], primary term [1]. current document has seqNo [14] and primary term [1]]
	at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:509)
	at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:420)
	at org.elasticsearch.action.bulk.BulkItemResponse.fromXContent(BulkItemResponse.java:135)
	at org.elasticsearch.action.bulk.BulkResponse.fromXContent(BulkResponse.java:198)
	at org.elasticsearch.client.RestHighLevelClient.parseEntity(RestHighLevelClient.java:1406)
	at org.elasticsearch.client.RestHighLevelClient.lambda$performRequestAsyncAndParseEntity$10(RestHighLevelClient.java:1284)
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:1334)
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:836)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:538)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:529)
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122)
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338)
	at org.apache.http.impl.nio.client.InternalRequestExecutor.inputReady(InternalRequestExecutor.java:83)
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591)
	... 1 common frames omitted
12:37:08.154 [flink-akka.actor.default-dispatcher-132] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Could not restart the job this-test (0112c0387c891788cf37a4fab90f26d5) because the restart strategy prevented it.
java.lang.RuntimeException: An error occurred in ElasticsearchSink.
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.checkErrorAndRethrow(ElasticsearchSinkBase.java:379)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.invoke(ElasticsearchSinkBase.java:304)
	at org.apache.flink.streaming.api.functions.sink.SinkFunction.invoke(SinkFunction.java:52)
	at org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:56)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:649)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:602)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamFilter.processElement(StreamFilter.java:40)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:202)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:105)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:300)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.elasticsearch.ElasticsearchException: Elasticsearch exception [type=version_conflict_engine_exception, reason=[e]: version conflict, required seqNo [8], primary term [1]. current document has seqNo [14] and primary term [1]]
	at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:509)
	at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:420)
	at org.elasticsearch.action.bulk.BulkItemResponse.fromXContent(BulkItemResponse.java:135)
	at org.elasticsearch.action.bulk.BulkResponse.fromXContent(BulkResponse.java:198)
	at org.elasticsearch.client.RestHighLevelClient.parseEntity(RestHighLevelClient.java:1406)
	at org.elasticsearch.client.RestHighLevelClient.lambda$performRequestAsyncAndParseEntity$10(RestHighLevelClient.java:1284)
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:1334)
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:836)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:538)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:529)
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122)
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338)
	at org.apache.http.impl.nio.client.InternalRequestExecutor.inputReady(InternalRequestExecutor.java:83)
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591)
	... 1 common frames omitted
12:37:08.155 [flink-akka.actor.default-dispatcher-132] INFO org.apache.flink.runtime.checkpoint.CheckpointCoordinator - Stopping checkpoint coordinator for job 0112c0387c891788cf37a4fab90f26d5.
12:37:08.155 [flink-akka.actor.default-dispatcher-132] INFO org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore - Shutting down
12:37:08.155 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Releasing slot [SlotRequestId{9225a682112ba3a8876a86624954f883}] because: Release multi task slot because all children have been released.
12:37:08.155 [flink-akka.actor.default-dispatcher-132] DEBUG org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Adding returned slot [AllocationID{ff0ef514b2463d2406ff304b42249356}] to available slots
12:37:08.183 [flink-akka.actor.default-dispatcher-132] INFO org.apache.flink.runtime.dispatcher.StandaloneDispatcher - Job 0112c0387c891788cf37a4fab90f26d5 reached globally terminal state FAILED.
12:37:08.183 [main] INFO org.apache.flink.runtime.minicluster.MiniCluster - Shutting down Flink Mini Cluster
12:37:08.184 [main] INFO org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint - Shutting down rest endpoint.
12:37:08.188 [flink-akka.actor.default-dispatcher-133] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Stopping TaskExecutor akka://flink/user/taskmanager_0.
12:37:08.188 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.jobmaster.JobMaster - Stopping the JobMaster for job this-test(0112c0387c891788cf37a4fab90f26d5).
12:37:08.188 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Disconnect TaskExecutor 44d9f797-9615-4b31-b456-531e5238ff73 because: Stopping JobMaster for job this-test(0112c0387c891788cf37a4fab90f26d5).
12:37:08.189 [flink-akka.actor.default-dispatcher-133] INFO org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager - Shutting down TaskExecutorLocalStateStoresManager.
12:37:08.191 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.jobmaster.JobMaster - Close ResourceManager connection cf9fe1aae908f5a6b873af96570f8b3b.
org.apache.flink.util.FlinkException: JobManager is shutting down.
	at org.apache.flink.runtime.jobmaster.JobMaster.postStop(JobMaster.java:365)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.postStop(AkkaRpcActor.java:105)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.postStop(FencedAkkaRpcActor.java:40)
	at akka.actor.Actor$class.aroundPostStop(Actor.scala:515)
	at akka.actor.UntypedActor.aroundPostStop(UntypedActor.scala:95)
	at akka.actor.dungeon.FaultHandling$class.akka$actor$dungeon$FaultHandling$$finishTerminate(FaultHandling.scala:210)
	at akka.actor.dungeon.FaultHandling$class.terminate(FaultHandling.scala:172)
	at akka.actor.ActorCell.terminate(ActorCell.scala:374)
	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:467)
	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483)
	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:260)
	at akka.dispatch.Mailbox.run(Mailbox.scala:224)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:234)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
12:37:08.203 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Suspending SlotPool.
12:37:08.204 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.jobmaster.slotpool.SlotPool - Stopping SlotPool.
12:37:08.206 [flink-akka.actor.default-dispatcher-132] INFO org.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopping dispatcher akka://flink/user/dispatcher951484a5-5535-45ec-9db6-af63189103d4.
12:37:08.206 [flink-akka.actor.default-dispatcher-132] INFO org.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher951484a5-5535-45ec-9db6-af63189103d4.
12:37:08.211 [ForkJoinPool.commonPool-worker-3] INFO org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint - Removing cache directory C:\Users\ADMINI~1\AppData\Local\Temp\flink-web-ui
12:37:08.212 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.resourcemanager.StandaloneResourceManager - Disconnect job manager 8269c6eee1ad13b55d68d6daa6c34887@akka://flink/user/jobmanager_1 for job 0112c0387c891788cf37a4fab90f26d5 from the resource manager.
12:37:08.212 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.resourcemanager.JobLeaderIdService - Found a new job leader null@null.
12:37:08.213 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Closing the SlotManager.
12:37:08.213 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Suspending the SlotManager.
12:37:08.213 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.resourcemanager.slotmanager.SlotManager - Unregister TaskManager f2876166ab70148059ed9f2f9a72cef9 from the SlotManager.
12:37:08.213 [flink-akka.actor.default-dispatcher-130] DEBUG org.apache.flink.runtime.taskexecutor.JobLeaderService - New leader information for job 0112c0387c891788cf37a4fab90f26d5. Address: null, leader id: null.
12:37:08.213 [flink-akka.actor.default-dispatcher-130] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - JobManager for job 0112c0387c891788cf37a4fab90f26d5 with leader id 8269c6eee1ad13b55d68d6daa6c34887 lost leadership.
12:37:08.216 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.rest.handler.legacy.backpressure.StackTraceSampleCoordinator - Shutting down stack trace sample coordinator.
12:37:08.218 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.io.disk.iomanager.IOManager - Shutting down I/O manager.
12:37:08.220 [flink-akka.actor.default-dispatcher-128] INFO org.apache.flink.runtime.dispatcher.StandaloneDispatcher - Stopped dispatcher akka://flink/user/dispatcher951484a5-5535-45ec-9db6-af63189103d4.
12:37:08.221 [flink-akka.actor.default-dispatcher-133] INFO org.apache.flink.runtime.io.disk.iomanager.IOManager - I/O manager removed spill file directory C:\Users\ADMINI~1\AppData\Local\Temp\flink-io-63de5759-3655-475c-900d-d03e75978cfe
12:37:08.221 [flink-akka.actor.default-dispatcher-133] INFO org.apache.flink.runtime.io.network.NetworkEnvironment - Shutting down the network environment and its components.
12:37:08.221 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Shutting down network connection manager
12:37:08.221 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.io.network.NetworkEnvironment - Shutting down intermediate result partition manager
12:37:08.222 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Releasing 0 partitions because of shutdown.
12:37:08.224 [flink-akka.actor.default-dispatcher-133] DEBUG org.apache.flink.runtime.io.network.partition.ResultPartitionManager - Successful shutdown.
12:37:08.229 [flink-akka.actor.default-dispatcher-133] INFO org.apache.flink.runtime.taskexecutor.JobLeaderService - Stop job leader service.
12:37:08.231 [flink-akka.actor.default-dispatcher-133] INFO org.apache.flink.runtime.taskexecutor.TaskExecutor - Stopped TaskExecutor akka://flink/user/taskmanager_0.
12:37:08.235 [flink-akka.actor.default-dispatcher-133] INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopping Akka RPC service.
12:37:08.244 [flink-akka.actor.default-dispatcher-132] DEBUG akka.event.EventStream - shutting down: StandardOutLogger started
12:37:08.257 [flink-akka.actor.default-dispatcher-133] INFO org.apache.flink.runtime.blob.PermanentBlobCache - Shutting down BLOB cache
12:37:08.258 [flink-akka.actor.default-dispatcher-133] INFO org.apache.flink.runtime.blob.TransientBlobCache - Shutting down BLOB cache
12:37:08.259 [flink-akka.actor.default-dispatcher-133] INFO org.apache.flink.runtime.blob.BlobServer - Stopped BLOB server at 0.0.0.0:53717
12:37:08.259 [flink-akka.actor.default-dispatcher-133] INFO org.apache.flink.runtime.rpc.akka.AkkaRpcService - Stopped Akka RPC service.
Exception in thread "main" org.apache.flink.runtime.client.JobExecutionException: java.lang.RuntimeException: An error occurred in ElasticsearchSink.
	at org.apache.flink.runtime.minicluster.MiniCluster.executeJobBlocking(MiniCluster.java:623)
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:123)
	at connector.es.EsConnectorDemo.main(EsConnectorDemo.java:103)
Caused by: java.lang.RuntimeException: An error occurred in ElasticsearchSink.
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.checkErrorAndRethrow(ElasticsearchSinkBase.java:379)
	at org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase.invoke(ElasticsearchSinkBase.java:304)
	at org.apache.flink.streaming.api.functions.sink.SinkFunction.invoke(SinkFunction.java:52)
	at org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:56)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:649)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$BroadcastingOutputCollector.collect(OperatorChain.java:602)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamFilter.processElement(StreamFilter.java:40)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:202)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:105)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:300)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: [test_index/m3mCLiSmQbugO4TXupHgrw][[test_index][0]] ElasticsearchException[Elasticsearch exception [type=version_conflict_engine_exception, reason=[e]: version conflict, required seqNo [8], primary term [1]. current document has seqNo [14] and primary term [1]]]
	at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:509)
	at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:420)
	at org.elasticsearch.action.bulk.BulkItemResponse.fromXContent(BulkItemResponse.java:135)
	at org.elasticsearch.action.bulk.BulkResponse.fromXContent(BulkResponse.java:198)
	at org.elasticsearch.client.RestHighLevelClient.parseEntity(RestHighLevelClient.java:1406)
	at org.elasticsearch.client.RestHighLevelClient.lambda$performRequestAsyncAndParseEntity$10(RestHighLevelClient.java:1284)
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:1334)
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:836)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:538)
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:529)
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122)
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448)
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338)
	at org.apache.http.impl.nio.client.InternalRequestExecutor.inputReady(InternalRequestExecutor.java:83)
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81)
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591)
	... 1 more
Disconnected from the target VM, address: '127.0.0.1:53711', transport: 'socket'

Process finished with exit code 1
